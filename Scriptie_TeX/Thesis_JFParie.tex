% Basic document and typesetting settings
\documentclass[a4paper, twoside, 11pt]{report}
\usepackage[acronym, nonumberlist, automake, nopostdot, nogroupskip, section]{glossaries}
\newcommand*{\glsgobblenumber}[1]{}
% \renewcommand*{\glsgobblenumber}[1]{#1}% uncomment for testing
\makeatletter
\renewrobustcmd*{\glsadd}[2][]{%
  \@gls@adjustmode
  \glsdoifexists{#2}%
  {%
    \def\@glsnumberformat{glsnumberformat}%
    \edef\@gls@counter{\csname glo@\glsdetoklabel{#2}@counter\endcsname}%
    \setkeys{glossadd}{#1}%
    \@gls@saveentrycounter%
    \@gls@setsort{#2}%
    \@@do@wrglossary{#2}%
  }%
}
\makeatother
\newglossary{symbols}{sym}{sbl}{Symbols}
\setglossarystyle{super}
\setlength\glsdescwidth{\textwidth}

\newglossaryentry{BN_structure}{
type=symbols,
name={\ensuremath{\mathcal{G}}},
description={Bayesian network structure, a directed acyclic graph}
}
\newglossaryentry{var}{
type=symbols,
name={\ensuremath{X_i}},
description={variable in a BN}
}
\newglossaryentry{n}{
type=symbols,
name={\ensuremath{n}},
description={total number of variables in a BN}
}
\newglossaryentry{i}{
type=symbols,
name={\ensuremath{i}},
description={indexation of variables in a BN, $1 \leq i \leq n$}
}
%independent
\newcommand\indep{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}
\newglossaryentry{indep}{
type=symbols,
name={\ensuremath{\indep}},
description={independent}
}
\newglossaryentry{var_set}{
type=symbols,
name={\ensuremath{\mathcal{X}}},
description={set of all variables in the BN}
}
\newglossaryentry{par_var}{
type=symbols,
name={\ensuremath{\text{Pa}_{X_i}}},
description={direct parents of variable $X_i$}
}
\newglossaryentry{non_des_var}{
type=symbols,
name={\ensuremath{\text{ND}_{X_i}}},
description={non-descendants of variable $X_i$}
}
\newglossaryentry{loc_indep}{
type=symbols,
name={\ensuremath{\mathcal{I}_l(\mathcal{G})}},
description={local independencies of $\mathcal{G}$}
}
\newglossaryentry{val_X_i}{
type=symbols,
name={\ensuremath{Val(X_i)}},
description={values that a random variable $X_i$ can take}
}
\newglossaryentry{x_i}{
type=symbols,
name={\ensuremath{x_i}},
description={assigned value to random variable $X_i$}
}
\newglossaryentry{bfX}{
type=symbols,
name={\ensuremath{\mathbf{X}}},
description={set of random variables}
}
\newcommand{\bfx}{{\mathbf{x}}}
\newglossaryentry{bfx}{
type=symbols,
name={\ensuremath{\bfx}},
description={set of assigned values to random variables}
}
\newglossaryentry{bfx_a}{
type=symbols,
name={\ensuremath{\mathbf{x}'}},
description={proposed sample}
}
\newglossaryentry{P}{
type=symbols,
name={\ensuremath{P}},
description={probability distribution over the BN, given by its CPTs}
}
\newglossaryentry{tilde_P}{
type=symbols,
name={\ensuremath{\widetilde{P}}},
description={estimation of $P$}
}
\newglossaryentry{T}{
type=symbols,
name={\ensuremath{T}},
description={total number of samples}
}
\newglossaryentry{t}{
type=symbols,
name={\ensuremath{t}},
description={indexation of samples, $1 \leq t \leq T$}
}
\newglossaryentry{sample_x}{
type=symbols,
name={\ensuremath{\mathbf{x}^{(t)}}},
description={sample of the BN at step $t$}
}
\newglossaryentry{l_i}{
type=symbols,
name={\ensuremath{l_i}},
description={indexation of the entries in the CPT of variable $X_i$, $1 \leq l \leq Val(X_i)$}
}
\newcommand{\C}{{\mathcal C}}
\newglossaryentry{C}{
type=symbols,
name={\ensuremath{\C}},
description={set with labels of all CPT-entries of all variables in the BN}
}
\newglossaryentry{k}{
type=symbols,
name={\ensuremath{k}},
description={used to denote the abbreviation of a variable name}
}
\newglossaryentry{kli}{
type=symbols,
name={\ensuremath{k(l_i)}},
description={label of all entries in the CPT corresponding to variable $X_i$}
}
\newglossaryentry{c_k_l_i}{
type=symbols,
name={\ensuremath{c_{ k(l_i)}}},
description={CPT-entry corresponding to label $k(l_i)$}
}
\newglossaryentry{textC}{
type=symbols,
name={\ensuremath{C}},
description={a collection of (arbitrary) CPT-labels}
}
\newglossaryentry{Cx}{
type=symbols,
name={\ensuremath{\C_\bfx}},
description={CPT-labels corresponding to state $\bfx$ of the BN}
}
\newglossaryentry{S_C}{
type=symbols,
name={\ensuremath{S_{C}}},
description={all possible (not necessarily feasible) states of the BN which could be created from $C$}
}
\newglossaryentry{Cxp}{
type=symbols,
name={\ensuremath{\C_\bfx^{\text{p}} }},
description={set with pruned CPT-labels, the BN is pruned around the state $\bfx$}
}
\newglossaryentry{Cxnp}{
type=symbols,
name={\ensuremath{\C_\bfx^{\text{np}}}},
description={set with non-pruned CPT-labels, the BN is pruned around the state $\bfx$}
}
\newcommand{\U}{{\mathcal{U}}}
\newglossaryentry{U}{
type=symbols,
name={\ensuremath{\U(\cdot)}},
description={uniform distribution over a set}
}
\newglossaryentry{Cpxy}{
type=symbols,
name={\ensuremath{\mathcal{C}_{\{\mathbf{x}, \mathbf{y}\}}^{\text{p}}}},
description={set with pruned CPT-labels, the BN is pruned around the states $\bfx$ and $\bfy$}
}
\newglossaryentry{Cnpxy}{
type=symbols,
name={\ensuremath{\mathcal{C}_{\{\mathbf{x}, \mathbf{y}\}}^{\text{np}}}},
description={set with non-pruned CPT-labels, the BN is pruned around the states $\bfx$ and $\bfy$}
}
\newglossaryentry{H}{
type=symbols,
name={\ensuremath{H}},
description={number of steps needed to make a pruned collection $\mathcal{C}_{\{\mathbf{x}, \mathbf{y}\}, h}^{\text{p}}$ and $\mathcal{C}_{\{\mathbf{x}, \mathbf{y}\}, h}^{\text{np}}$, such that $\bfx$ can make a transition to $\bfy$}
}
\newglossaryentry{Cpxyh}{
type=symbols,
name={\ensuremath{\mathcal{C}_{\{\mathbf{x}, \mathbf{y}\},h}^{\text{p}}}},
description={$h$-th step in creating a set with pruned CPT-labels $\mathcal{C}_{\{\mathbf{x}, \mathbf{y}\}}^{\text{p}}$, such that $\bfx$ can make a transition to $\bfy$}
}
\newglossaryentry{Cnpxyh}{
type=symbols,
name={\ensuremath{\mathcal{C}_{\{\mathbf{x}, \mathbf{y}\},h}^{\text{np}}}},
description={$h$-th step in creating a set with non-pruned CPT-labels $\mathcal{C}_{\{\mathbf{x}, \mathbf{y}\}}^{\text{np}}$, such that $\bfx$ can make a transition to $\bfy$}
}
\newglossaryentry{Rhxy}{
type=symbols,
name={\ensuremath{{R}_h (\mathbf{x} \to \mathbf{y})}},
description={transition probability to get from $\bfx$ to $\bfy$ in the $h$-th step}
}
\newglossaryentry{gamma}{
type=symbols,
name={\ensuremath{\gamma}},
description={acceptance probability in Metropolis sampling}
}

\setacronymstyle{long-short}
\newacronym{BN}{BN}{Bayesian network}
\newacronym{MCMC}{MCMC}{Markov chain Monte Carlo}
\newacronym{DAG}{DAG}{directed acyclic graph}
\newacronym{CPT}{CPT}{conditional probability table}
\newacronym{MLN}{MLN}{Markov logic network}
\newacronym{SAT}{SAT}{satisfiability problem}
\newacronym{HFS}{HFS}{hybrid forward sampling}

\makeglossaries
\renewcommand{\glsnamefont}[1]{\normalfont{#1}}

%\usepackage{geometry}
\usepackage[english]{babel}
\usepackage[hidelinks]{hyperref}
\usepackage{comment}
\usepackage{cite}
\usepackage{adjustbox}
\usepackage{enumitem}
	\setenumerate{itemsep = 0.1cm}
\usepackage[font = small, margin=0.5cm]{caption}
\usepackage{subcaption}
%\usepackage{fullpage} % messes up the margins headers/footers
\usepackage{amssymb}
\usepackage{tabularx}
\usepackage{amsmath}
\usepackage[utf8]{inputenc}
\usepackage[section]{placeins}
\usepackage{graphicx}
\usepackage{dsfont}
\usepackage{caption}
\usepackage{lipsum}
\usepackage[hang,flushmargin]{footmisc} 
\usepackage{cleveref}
\usepackage{multicol}
\usepackage[numbers,square,sort]{natbib}
\usepackage{algorithmicx}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{subcaption}
\usepackage{float} 
\usepackage{cancel}
\usepackage{multirow} 
\usepackage{booktabs} 
\usepackage{varioref} 
\usepackage{filecontents}
\usepackage[outdir=./]{epstopdf}
\usepackage{tabto}
\NumTabs{4}
\usepackage{wrapfig}
\usepackage{pgf}
\usepackage{color}
\usepackage{hyperref}
\hypersetup{colorlinks, breaklinks, urlcolor=black, linkcolor=black, citecolor=black}
\usepackage{pgfplots}
\usepackage{array}
\usetikzlibrary{shapes, arrows}
\tikzset{
    events/.style={ellipse, draw, align=center},
}
\usepackage{filecontents}
\setlength\parindent{24pt}
\usepackage[hmarginratio=1:1, left=25mm, top=25mm, bottom=30mm]{geometry}

\AtBeginDocument{\renewcommand{\bibname}{References}}

\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}

%Font and spacing of words/lines
\setlength{\textfloatsep}{5pt}
\usepackage{libertine}
\usepackage{setspace}
	\setstretch{1.05}
\usepackage[tracking = true, letterspace = 100]{microtype}

%Sectioning settings
\usepackage{abstract}
	\renewcommand{\abstractnamefont}{\scshape\sffamily\Large}
	\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
	
\usepackage{titlesec}
	\titleformat	
		\chapter[display]
			\huge
  				{\textsc{\lsstyle\chaptertitlename\ \thechapter}}{0pt}{\Huge\bfseries}
	\titleformat
		\section
  			{\bfseries\normalfont\Large}{\thesection}{1em}{}
	\titleformat
		\subsection
			{\bfseries\normalfont\large}{\thesubsection}{1em}{}
	\titlespacing*{\section}{0cm}{1pc}{1pc}
	
\titleformat{\chapter}
  {\bfseries\huge}{\normalfont{\lsstyle\chaptertitlename\ \thechapter}}{1em}{}
  
\titlespacing*{\chapter}{0pt}{0pc}{1.5pc}
\titlespacing*{\section}{0pt}{1.5pc}{.5pc}
\titlespacing*{\subsection}{0pt}{1.5pc}{.5pc}

%Headers and footers
\usepackage{fancyhdr}
	\setlength{\headheight}{13.59999pt}
	\pagestyle{plain}
		{
			\fancyhf{}
			\renewcommand{\headrulewidth}{0pt}
			\fancyfoot[C]{\thepage}
		}
	\pagestyle{fancy}
		{
			\fancyhf{}
			\renewcommand{\sectionmark}[1]{\markright{\thesection~ - ~#1}}
			\renewcommand{\chaptermark}[1]{\markboth{\chaptername~\thechapter~ - ~#1}{}}
			\fancyhead[LO]{\nouppercase{\textsc\rightmark}}
			\fancyhead[RE]{\nouppercase{\textsc\leftmark}}
			\fancyfoot[C]{\thepage}
		}


%Pictures
\usepackage{graphicx}
\usepackage{mathtools}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

% Tikz
\usepackage{tikz}
	\usetikzlibrary{positioning}
    \usetikzlibrary{calc}
\usepackage{tikz-qtree}
\usetikzlibrary{arrows,calc,plotmarks,intersections}
\tikzset{>=stealth', help lines/.style={dashed, thick}, axis/.style={<->}, important line/.style={thick}, connection/.style={thick, dotted},}
\usetikzlibrary{shapes.geometric,positioning}

% Math packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathrsfs}
	
%Theorem commands
\theoremstyle{plain}
	\newtheorem{thm}{Theorem}[chapter]
	\newtheorem{lem}[thm]{Lemma}
	\newtheorem{con}[thm]{Conjecture}
\theoremstyle{definition}
	\newtheorem{definition}[thm]{Definition}
	\newtheorem{example}[thm]{Example}
	\newtheorem{exmps}[thm]{Examples}
	\newtheorem{prop}[thm]{Proposition}
\theoremstyle{remark}
	\newtheorem*{remark}{Remark}
	\newtheorem*{remarks}{Remarks}
	\newtheorem{notation}[thm]{Notation}


% Probability notations
% Definition commands

\newcommand{\A}{{\mathcal A}}
\newcommand{\B}{{\mathcal B}}
\newcommand{\E}{{\mathbb E}}
\newcommand{\F}{{\mathcal F}}
\newcommand{\G}{{\mathcal G}}
\renewcommand{\H}{{\mathcal H}}
\newcommand{\I}{{\mathcal{I}}}
\newcommand{\M}{{\mathcal M}}
\newcommand{\Q}{{\mathcal{Q}}}
\newcommand{\X}{{\mathcal{X}}}

\newcommand{\calP}{{\mathcal{P}}}
\newcommand{\Var}{{\text{Var}}}

\newcommand{\one}[1]{\mathrm{#1}}
\newcommand{\two}[2]{\mathrm{#1#2}}
\newcommand{\three}[3]{\mathrm{#1#2#3}}
\newcommand{\four}[4]{\mathrm{#1#2#3#4}}

\newcommand{\ps}{\textit{prune sampling }}
\newcommand{\psp}{\textit{prune sampling. }}
\newcommand{\Ps}{\textit{Prune sampling }}

\renewcommand{\gg}{{\text{g} }}
\newcommand{\gT}{{\text{g}_\text{T} }}
\newcommand{\gF}{{\text{g}_\text{F} }}
\renewcommand{\ss}{{\text{s} }}
\newcommand{\sT}{{\text{s}_\text{T} }}
\newcommand{\sF}{{\text{s}_\text{F} }}
\newcommand{\rr}{{\text{r} }}
\newcommand{\rT}{{\text{r}_\text{T} }}
\newcommand{\rF}{{\text{r}_\text{F} }}


%mathbf
\newcommand{\bfe}{{\mathbf{e}}}
\newcommand{\bfy}{{\mathbf{y}}}
\newcommand{\bfX}{{\mathbf{X}}}
\newcommand{\bfE}{{\mathbf{E}}}

%color-text
\newcommand{\red}[1]{{\textcolor{red}{#1}}}

% number systems

\def\N{{\mathbb N}}
\def\bbZ{{\mathbb Z}}
\def\bbQ{{\mathbb Q}}
\def\bbR{{\mathbb R}}
\def\bbC{{\mathbb C}}

\renewcommand{\P}{{\mathbb P}}

% Renewed definition commands
\renewcommand{\S}[1]{\mathscr{#1}}

% Renewed commands
\renewcommand{\epsilon}{\varepsilon}

\begin{document}

%\newgeometry{hmarginratio = 1:1}


%% new commands



% Titlepage

\begin{titlepage}
	\centering
	\vspace{1cm}
	
\scshape\sffamily{\Large master thesis jurriaan parie }\\[1.5cm]

\HRule \\[0.4cm]
{ \huge \scshape\sffamily{ performance of sampling methods \vskip 0.25cm for deterministic bayesian networks}} \\[0.3cm]
\HRule \\[1.5cm]

\scshape\sffamily{ \Large msc mathematical sciences, \\ utrecht university }

\vfill
	
\large \scshape\sffamily{supervised by:}

\vspace{2pc}
	
\noindent\makebox[0.5\linewidth][c]{%
\begin{minipage}[t!]{.47\textwidth}
	{\large \scshape\sffamily{dr. frank philipson} } \\ \\
	\scshape\sffamily{cyber security and robustness, tno} \\
	\centering
	\includegraphics[scale=0.54]{tno_logo_zwart.jpg}
\end{minipage}}
\hfill
\begin{minipage}[t!]{.47\textwidth}
	{ \large \scshape\sffamily{prof. dr. gerard barkema} } \\ \\
	\scshape\sffamily{information and computing sciences, utrecht university}
	\centering
	\includegraphics[height = 7pc]{UU_logo_EN_RGB.jpg}
\end{minipage}

\vfill

\large \scshape\sffamily{september 14, 2018}

	
\end{titlepage}


\pagenumbering{roman}
%\pagenumbering{arabic}

\pagestyle{plain}

% Abstract

\begin{abstract}
The performance of the recently introduced \ps algorithm \cite{phillipson2018} is characterised for various types of Bayesian networks and compared to the popular Markov chain Monte Carlo (MCMC) sampling methods Gibbs- and Metropolis sampling. We devised a procedure to obtain the performance of the MCMC sampling methods in the limit of infinite simulation time, extrapolated from relatively short simulations. This approach was used to conduct a study to compare the accuracy, rate of convergence and the time consumption of the sampling methods. We show that Markov chains created by \textit{prune sampling} always converge to the desired posterior distribution, also for networks where conventional Gibbs sampling fails. {Beside that, we demonstrate} that \ps outperforms {Gibbs sampling -- arguably the most widely used MCMC inference technique --} at least for a class of BNs. Though, this tempting feature comes at a price. In the first version of \textit{prune sampling}, the procedure to choose a configuration of the BN for the next iteration is rather time intensive. Our conclusion is that \ps is {a competitive} method for all types of small and medium sized BNs, but standard methods perform better for all types of large BNs. Ultimately, we improved  the first version of \ps by providing sophisticated solutions for its flaws.

\blfootnote{\noindent Part of this thesis will be published as \textit{Prune sampling: a MCMC inference technique for discrete and deterministic Bayesian networks}} 
\end{abstract}

%a competitive
%former: the preferred

%Gibbs sampling
%former: standars sampling techniques

%Beside that, we demonstrate that
%former: We show

%In the first version of \ps, for large BNs the procedure to choose the next iteration step uniformly is rather time intensive.
%former: In the first version of \ps, the procedure to choose uniformly a configuration for large BNs for the next iteration is rather time intensive.

% Contents

\tableofcontents

\clearpage

\pagenumbering{arabic}

\restoregeometry


%Introduction

\chapter{Introduction}\label{intro}
This thesis is about Bayesian network inference. In particular, it is about the performance of Markov chain Monte Carlo sampling methods in presence of deterministic relations, which form an important class of approximate inference techniques for Bayesian networks. In this first chapter, we give a brief overview of the study we perform in this master thesis.

\section{Bayesian networks and inference}
A Bayesian network (BN) is a probabilistic model that represents a set of random variables and their conditional dependencies. One could represent a BN graphically by considering a directed acyclic graph where the set of nodes is induced by the set of random variables and where the set of edges is given by the conditional dependencies between these random variables. Assuming that instances fall into one of a number of mutually exclusive and exhaustive classes, discrete BNs are used to model probabilistic relationships. As an illustration, BNs model genetic linkage \cite{fishelson2004}, causal reasoning \cite{pearl2014probabilistic} and defence systems \cite{phillipson2015modelling}. For all of these models, BNs are used to answer probabilistic queries about variables and their relationships. An interesting feature of BNs is that the network can be used to find out updated knowledge of the state of a subset of variables when other variables (the evidence variables) are observed. This process, of computing the posterior distribution of variables when evidence is given, is called inference. Though, exact inference in BNs is often too computationally intensive. On the other hand, approximate inference methods have to deal with a lack of convergence and often perform poorly in the presence of determinism \cite{koller2009probabilistic, poon2006sound, gogate2011samplesearch}. Therefore, a plethora of different inference strategies have been developed \cite{nasrabadi2007pattern, nielsen2009bayesian, koller2009probabilistic, pearl2014probabilistic}.

\section{Goals and approach of this research project}
In order to improve the reliability of approximate inference methods, at TNO an unprecedented Markov Chain Monte Carlo (MCMC) approximate inference method named \ps was created. In this research project, I characterise the performance of the first implemented version of \ps for discrete and deterministic BNs. We devised a procedure to obtain the performance of MCMC sampling methods in the limit of infinite simulation time, extrapolated from relatively short simulations. This approach was used to conduct a study to compare the accuracy, rate of convergence and the time consumption of \ps with two conventional MCMC sampling methods: Gibbs- and Metropolis sampling. In addition, we disclose the pitfalls of \ps and show how this first version could be improved. Results of this study will be published in \textit{Prune sampling: a MCMC inference technique for discrete and deterministic Bayesian networks} \cite{phillipson2018}.


\section{Overview of the thesis}
We start introducing the BN framework, inference techniques and their shortcomings in Chapter 2. In Chapter 3, we introduce the concept and elaborate on the implementation of \textit{prune sampling}. Consecutively, in Chapter 4, we present the performance of \ps in terms of accuracy, the rate of convergence and time consumption compared with Metropolis- and Gibbs sampling. In Chapter 5, we propose solutions to the flaws of \ps and and discuss results of improved versions of the algorithm.

\chapter{Bayesian network inference}\label{ch:2}
In this chapter, we introduce the main concepts our study: the framework of Bayesian networks (BNs), the task of doing BN inference and \gls{MCMC} sampling methods for BNs. We highlight the pros and cons of commonly used MCMC inference techniques. Such that -- later on -- we can make a comparison between the performance of those methods and the \ps method more clearly.

\section{Bayesian networks}
First, we introduce the concept of a BN structure and its corresponding probabilistic methodology.
\begin{definition}[Bayesian network]
A \gls{BN} structure $\gls{BN_structure}$ is a \gls{DAG} whose nodes represent random variables $\gls{var_set} = (X_1, \ldots , X_{\gls{n}})$. Let $\gls{par_var}$ denote the direct parents of $\gls{var}$ in $\G$ and $\gls{non_des_var}$ denote the variables in the graph that are non-descendants of $X_i$. Then $\G$ encodes the following set of conditional independence assumptions, called the local independencies, and denoted by $\gls{loc_indep}$:
\begin{align*}
\text{for each variable $X_i$: $(X_{\gls{i}} \gls{indep} \text{ND}_{X_i} | \text{Pa}_{X_i})$}.
\end{align*}
In other words, the local independencies state that each node $X_i$ is conditionally independent of its non-descendants given its parents \citep[p.~57]{koller2009probabilistic}.
\end{definition}

When dealing with spaces composed solely of discrete-valued random variables, to each node $X_i$ we assign a state $x_i \in Val(X_i)$. Here, $\gls{val_X_i}$ denotes the set of values that a random variable $X_i$ can take. We display the conditional probability distribution $P(X_i | \text{Pa}_{X_i})$ in a \gls{CPT}, where
\begin{align*}
\sum_{i \in \{1, \ldots , n\}} P(\gls{x_i} | \text{Pa}_{X_i}) = 1.
\end{align*}
So, a BN exists of a graph with a collection of local probability distributions, given in CPTs. Together, these local probability distributions give the joint probability distribution of the BN. We use $\gls{bfX} \subseteq \X$ to denote a set of random variables, while $\gls{bfX}$ denotes an assignment of values to the variables in this set. For convenience, a state (or configuration) of a BN is denoted as $\bfx = (x_1, \ldots , x_n)$ and $\gls{P}(\bfx)$ denotes the probability of the BN having this state $\gls{bfx}$. Next, we introduce the event called determinism \citep[p.~158]{koller2009probabilistic}.
\begin{definition}[Deterministic relation]
The CPT contains one of more zeros. That is, there exists a function $f: Val(\text{Pa}_{X_i}) \to Val(X_i)$, such that
\begin{align*}
P(x_i | \text{Pa}_{X_i}) =
\begin{cases}
1 & x_i = f(\text{Pa}_{X_i}) \\ 
0 & \text{otherwise}.
\end{cases}
\end{align*} 
\end{definition}
The above introduced concepts are all depicted in Example \ref{ex:rain-sprinkler}.
\begin{example}\label{ex:rain-sprinkler}
Consider the \textit{Rain-Sprinkler} BN in Figure \ref{rainBN}. In this model, one could consider the event of grass being wet ($\gg$) as a results of two causes: either a sprinkler ($\ss$) is on or it is raining ($\rr$). Beside that, it is supposed that the rain has a direct effect on the use of the sprinkler. All three variables have two possible values, T (for true) and F (for false). From the CPTs it becomes clear that when it rains, the sprinkler is usually not turned on, i.e. $P( \sT |  \rT) = 0.01$. The counter intuitive state of the BN, that the grass is wet given it is not raining and the sprinkler is off: $\bfx = (\rF,  \sF, \gT)$, is excluded by the deterministic relation $P(\gT | \rF,  \sF) = 0$.  Taking the fixed (topological) order of the variables $R, S, G$ into account, the joint probability function is given by
\begin{align}
P(R, S, G) = P(G | R, S) P(S|R) P(R).
\label{eq:jointprob}
\end{align}
This BN can answer queries like \textit{what is the probability that it is raining, given the grass is wet?} by using the conditional probability formula and summing over all (auxiliary) variables
\begin{align}
P(R = \rT | G = \gT) = \frac{P(R = \rT, G = \gT)}{P(G = \rT)} = \frac{\sum_{S \in \{T,F\}} P(R = \rT, S, G = \gT)}{\sum_{R, S \in \{T,F\}} P(R, S, G = \gT)}.
\label{eq:conditional-summation}
\end{align}
\end{example}
More background concerning the mathematical representation of BNs and its methodology could be found in \cite{koller2009probabilistic}, Chapter~3; \cite{nielsen2009bayesian}, Chapter~2; \cite{pearl2014probabilistic}, Chapter~2. 
\begin{center}
\begin{figure}[t!]
\centering
\begin{tikzpicture}[node distance=1.2cm, >=triangle 60]
\node [events] (s) {Sprinkler};
\node [events,  right=of s] (r) {Rain};
\node [events,  below right=of s] (g) {Grass wet};


\draw [->] (r) -- (s);
\draw [->] (r) -- (g);
\draw [->] (s) -- (g);

{\small
\node [right = 2cm of r] (t_r) {
    \begin{tabular}{|c||c|} \hline
    	$\text{r}_\text{T}$ & $0.2$\\ \hline
    	$\text{r}_\text{F}$ & $0.8$ \\ \hline
    \end{tabular}
    };
    
\node [left = 2cm of s] (t_s) {
    \begin{tabular}{|c||c|c|} \hline
	& $\text{r}_\text{T}$ & $\text{r}_\text{F}$    \\ \hline \hline
	$\text{s}_\text{T}$ & 0.01 & 0.4   \\ \hline
	$\text{s}_\text{F}$ & 0.99 & 0.6 \\ \hline
\end{tabular}
    };
    
\node [below left = 1cm of g] (t_g) {
    \begin{tabular}{|c||c|c|c|c|} \hline
	& $\text{r}_\text{T},\ \text{s}_\text{T}$ & $\text{r}_\text{T},\ \text{s}_\text{F}$ & $\text{r}_\text{F},\ \text{s}_\text{T}$ & $\text{r}_\text{F},\ \text{s}_\text{F}$  \\ \hline \hline
	$\text{g}_\text{T}$ & 0.99 & 0.8 & 0.9 & 0  \\ \hline
	$\text{g}_\text{F}$ & 0.01 & 0.2 & 0.1 & 1 \\ \hline
\end{tabular}
    };
}
    
\draw [dotted] (r) -- (t_r);
\draw [dotted] (s) -- (t_s);
\draw [dotted] (g) -- (t_g);

\end{tikzpicture}
\caption{a BN structure and corresponding CPTs are used to model the event of grass being wet (g) as a results of two causes: either a sprinkler (s) is on or it is raining (r).}
\label{rainBN}
\end{figure}
\end{center}
\vspace{-1.9pc}
\section{Inference}\label{sec:inference}
The task of answering types of questions as \textit{what is $P(R = \text{r}_\text{T} | G = \text{g}_\text{T})$?} is called \textit{inference}. Below, we describe how one could answer such queries by computing the exact probability. \\

When values of variables are known, or are \textit{given}, we call this set $\bfE \subset \X$ evidence. Now, we can formulate the main goal of our this study as: given a set of evidence $\bfE = \bfe$ and nodes of interest $\bfX \subset \X$, such that $\bfE \cap \bfX = \emptyset$, what is the probability distribution $P(\bfX | \bfE = \bfe)$? Answering this type of questions is called \textit{inferring unobserved variables}. We write $P$ as the posterior probability distribution of interest, with reduced CPTs according to the evidence nodes. In the next example, we return to the \textit{Rain-Sprinkler} BN to give an illustration of this type of inference.
\begin{example}\label{ex:exact-marg}
Again, consider the BN from Figure \ref{rainBN}. We show how the question in Example \ref{ex:rain-sprinkler} -- \textit{what is $P(R = \text{r}_\text{T} | G = \text{g}_\text{T})$?} -- could be computed explicitly. Using the expansion for the joint probability function from Equation \ref{eq:jointprob} and the conditional probabilities from the CPTs, one could evaluate each term in the numerator and denominator of Equation \ref{eq:conditional-summation} in the way we evaluate
\begin{align*}
P(R = \rT, S = \sF, G = \gT) &= P(G = \gT | R = \rT, S = \sF) P(S = \sF | R = \rT) P(R = \rT) \\
&= 0.8 \cdot 0.99 \cdot 0.2 \\
&= 0.1584. 
\end{align*}
Doing these calculations for all cases, one will obtain
\begin{align*}
P(R = \rT | G = \gT) &= \frac{0.00198_{\rT, \sT, \gT} + 0.1584_{\rT, \sF, \gT} }{0.00198_{\rT, \sT, \gT} + 0.288_{\rF, \sT, \gT} + 0.1584_{\rT, \sF, \gT} + 0.0_{\rF, \sF, \gT}}\\
& = \frac{891}{2491} \approx 0.3577.
\end{align*}
Hence, the probability that it is raining, given the grass is wet is approximately 36\%.
\end{example}
The procedure described in Example \ref{ex:exact-marg} is called \textit{exact marginalization}. It illustrates that in order to do inference, there is not always need for an explicit joint distribution. Though, when we deal with more complex BNs, \textit{exact marginalization} is still vulnerable for an exponentially blow up of the number of computations to be executed. In general, all exact inference methods -- variable elimination, clique tree propagation, recursive conditioning et cetera -- have to execute computations that are exponential in the network's treewidth (a measure for graph complexity). To make all of those concepts detailed here is out of the scope of this thesis. Therefore, for a comprehensive discussion of those methods we refer to \cite{koller2009probabilistic}, Chapter~9; \cite{nielsen2009bayesian}, Chapter~4. \\
One way to avoid the exponential character of exact inference techniques, is to consider approximate inference methods. In order to do so, in the next section, we introduce how samples of states of BNs could be generated by using Markov chain Monte Carlo simulations.

%In cases where much of the evidence is at the leaves of the network, forward sampling techniques for example are essentially sampling from the prior distribution, which is often very far from the desired posterior. 

%\subsection{Exact algorithms}
%\subsection{Approximation algorithms}

%answer queries of the form

\section{Approximate sampling methods}\label{sec:approx-inf}
Approximate sampling methods extract characteristics of the BN by applying statistics on a large bunch of generated samples. These samples are generated according to a heuristic related to the BN structure and corresponding CPTs. In this section, we show how unobserved variables could be inferred based on this bunch of samples and which heuristic Metropolis- and Gibbs sampling use to create samples.\\ 

For now, consider we have a bunch of $6$ samples. The next example illustrates the key concept of all approximate inference techniques.
\begin{example}\label{ex:sampling}
Consider the BN in Figure \ref{rainBN}. Let \rr be our variable of interest and suppose $\bfx^{(1)}, \ldots , \bfx^{(6)}$ are independent and identically distributed (i.i.d.) samples of $(R, S, G)$ created by a certain sampling heuristic. The bunch of $6$ samples is given by
\begin{multicols}{2}
\begin{enumerate}
\item $\bfx^{(1)} = ( R^{(1)} = \rF, S^{(1)} = \sT,  G^{(1)} = \gT)$
\item $\bfx^{(2)} = ( R^{(2)} = \rT, S^{(2)} = \sF,  G^{(2)} = \gT)$
\item $\bfx^{(3)} = ( R^{(3)} = \rF, S^{(3)} = \sT,  G^{(3)} = \gT)$
\item $\bfx^{(4)} = ( R^{(4)} = \rF, S^{(4)} = \sT,  G^{(4)} = \gF )$
\item $\bfx^{(5)} = ( R^{(5)} = \rT, S^{(5)} = \sT,  G^{(5)} = \gT)$
\item $\bfx^{(6)} = ( R^{(6)} = \rF, S^{(6)} = \sF,  G^{(6)} = \gF)$.
\end{enumerate}
\end{multicols}
%Here, $\textasteriskcentered$ denotes that any value could be assigned to the corresponding variable, though (in this context) which values exactly is not relevant. 
\noindent Then, the probability of $R = \text{r}_\text{T}$ can be approximated by 
\begin{align*}
\gls{tilde_P}_6(R = \rT) = \E[ \mathds{1}_{R = \rT} ] = \sum_{t=1}^6 \mathds{1}_{R^{(t)} = \rT} = \frac{2}{6},
\end{align*}
where $\mathds{1}_{R = \rT}$ is the indicator function of the event $R = \rT$.
\end{example}
In general, for a variable of interest $X$ with $\gls{T} \in \N$ (not te be confused with T  for true) i.i.d. samples the probability of $X = x$ can be approximated by 
\begin{align*}
\widetilde{P}_T(X = x) = \E[ \mathds{1}_{X=x} ] = \sum_{t=1}^T \mathds{1}_{X^{(t)} = x}.
\end{align*}
A plethora of techniques have been develop to create samples $\bfx^{(1)}, \ldots \bfx^{(T)}$. Again, discussing all those methods here in detail is beyond the scope of this thesis. For an overview of approximate sampling techniques and its limitations we refer to \cite{koller2009probabilistic}, Chapter 12; \cite{nielsen2009bayesian} Chapter 4. In the next subsection, we focus on how samples of a BN can be generated using Markov chain Monte Carlo methods. 

\subsection{Markov chain Monte Carlo sampling}\label{sec:mcmc}
We introduce the concept of Markov chain Monte Carlo sampling and explain under which conditions the Markov chain guarantee convergence to the desired posterior distribution. Furthermore, we give an illustration how Metropolis sampling could be used on the \textit{Rain-Sprinkler} BN. \\

In contrast to Example \ref{ex:sampling}, suppose that sample $\gls{sample_x}$ is not created i.i.d. for all $\gls{t} \geq 1$. But we create sample $\bfx^{(t+1)}$ by tweaking the state of sample $\bfx^{(t)}$ according to a certain heuristic. Repeating this process yields the Markov chain $(\bfx^{(t)})_{t \in \N_0}$. Repeating this often -- for $t = 1, \ldots T$ with large $T$  -- this process is called \textit{Markov chain Monte Carlo} (MCMC) sampling. 
Due to a cleverly chosen heuristic, MCMC methods construct a Markov chain such that, although the first sample may be generated from the prior distributions, successive samples are generated from distributions that provably get closer and closer to the desired posterior distribution. It could be shown \citep[p.~517]{koller2009probabilistic} that $\widetilde{P}_T \to P$ as $T \to \infty$. In order to use this tempting feature of MCMC methods, we need to guarantee that the limit of this process exists and is unique. Since we only consider Markov chains on finite state spaces, from the theory of Markov chains we know that if a Markov chain is regular and reversible with respect to a distribution $\pi$, then $\pi$ is the unique stationary distribution. These notions are defined below.


%In cases where much of the evidence is at the leaves of the network, forward sampling techniques for example are essentially sampling from the prior distribution, which is often very far from the desired posterior. 

\begin{definition}[Regular Markov chain]
A Markov chain is said to be regular if there exists some number $k \in \N$ such that for every $\bfx, \bfx' \in Val(\bfX)$ the probability of getting from $\bfx$ to $\gls{bfx_a}$ -- denoted as $(\bfx \to \bfx')$ -- in exactly $k$ steps, is $> 0$. 
\end{definition}

\begin{definition}[Reversible Markov chain]
A finite-state Markov chain $Q$ is called reversible if there exists a unique distribution $\pi$ such that for all states $\bfx$ and $\bfx'$
\begin{align}
\pi(\bfx) Q(\bfx \to \bfx') = \pi(\bfx') Q(\bfx' \to \bfx).
\end{align}
\end{definition}

\begin{definition}[Stationary distribution]
A distribution $\pi$ is a stationary distribution for a Markov chain Q if
\begin{align}
\pi(\bfx') = \sum_{\bfx \in Val(\bfX)} \pi(\bfx) Q(\bfx \to \bfx').
\end{align}
\end{definition}
A heuristic that generates a Markov chain that tend to be regular and reversible is \textit{Metropolis sampling}. In the context of BN sampling, it follows the next procedure.
\begin{definition}[Metropolis sampling]
\leavevmode
\makeatletter
\@nobreaktrue
\makeatother
\vspace{0.5pc}
\begin{itemize}
\item Select an initial state $\bfx^{(0)}$ of the BN;
\item for each iteration $0 < t \leq T$: create a candidate sample $\bfx'$ by drawing a value from a proposed distribution. Here, for all $X_i$ we draw uniformly random a value from $Val(X_i)$;
%We could consider a normal distribution being `centered' on $X_i = x_i$ as making a random one-to-one representation of $Val(X_i) = \{x_1, \ldots , x_m \}$ (according to the fixed ordening) to the set $\{- \floor*{\frac{m}{2}}, \floor*{\frac{m}{2}}\}$. Then, we sample a random number $u$ from a normal distribution with mean that corresponds to the integer representing the variable of interest. According to specific boundaries we end up in a new proposed state.
\item determine the acceptance ratio $\gls{gamma} = \min \big( 1, \frac{P(\bfx')}{P(\bfx^{(t-1)})} \big)$ from the CPTs;
\item generate a uniform random number $u \in [0,1]$;
\begin{itemize}
\item if $u \leq \gamma$ then $\bfx^{(t)} = \bfx'$;
\item if $u > \gamma$ then $\bfx^{(t)} = \bfx^{(t-1)}$.
\end{itemize}
\end{itemize}
The above construction allows us to produce a Markov chain for an arbitrary stationary distribution. Though, in order to guarantee convergence to the desired distribution, we point out that the constructed chain still needs to be regular. This property does not follow directly from the construction. Under which conditions Metropolis sampling guarantees convergence is discussed in \citep[p.~505]{koller2009probabilistic}.
\end{definition}
In the next example, we show how Metropolis sampling works out on the \textit{Rain-Sprinkler} network.
\begin{example}[Metropolis sampling]
Consider the BN in Figure \ref{rainBN}. Suppose that we have the initial state 
\begin{align*}
\bfx^{(0)} = (R^{(0)} = \rT, S^{(0)} = \sF, G^{(0)} = \gT)
\end{align*}
and no evidence is available. We select $R^{(1)}$ according the distribution $P(R^{(1)}=\rT)=P(R^{(1)}=\rF) = 0.5$. Repeating this for $S$ and $G$, one could obtain
%In order to generate a sample $R^{(1)}$, according to a normal distribution, we could consider a normal distribution being `centered' on $R^{(0)} = \rT$ as making a one-to-one representation of $Val(R) = \{\rT, \rF\}$ to the set $\{0, 1\}$. Then, we can sample a random number $u$ according a standard normal distribution. Then, if $u \leq 0$: $X^{(1)} = \rT$ and if $u > 0: X^{(1)} = \rF$. 
\begin{align*}
\bfx' = (R' = \rT, S' = \sF, G' = \gF).
\end{align*}
We determine $\gamma$ as
\begin{align*}
\gamma = \frac{P(R' = \rT, S' = \sF, G' = \gF)}{P(R^{(0)} = \rT, S^{(0)} = \sF, G^{(0)} = \gT)} = \frac{0.0396}{0.1584} = 0.25. 
\end{align*}
Then, we $\bfx^{(1)} = \bfx'$ if the uniform random number $u \in [0,1]$ is smaller than $0.25$, otherwise $\bfx^{(1)} = \bfx^{(0)}$.
\end{example}
Repeating this procedure, we are able to generate $T$ samples of the BN. Ultimately, from this bunch of samples we can do inference as described in Example \ref{ex:sampling}. When we adjust the proposal distribution of Metropolis sampling, we could obtain a special case of Metropolis sampling called \textit{Gibbs sampling}. 
\subsection{Gibbs sampling}
Gibbs sampling \cite{geman1984stochastic} is one of the most popular MCMC methods to date.  We show how Gibbs sampling is related to Metropolis sampling and how regularity and reversibility could break down due to the appearance of deterministic relations in the BN.
\begin{definition}[Gibbs sampling]
Let $(X_1, \ldots , X_n)$ be an arbitrary ordering of the variables in $\G$. The Gibbs sampling algorithm begins with a random assignment $\bfx^{(0)}$ to all variables in the BN. Then, for $t = 1, \ldots, T$ it performs the following $T$ Gibbs iterations. For $i=1, \ldots, n$, it generates a new value $x_i^{(t)}$ for variable $X_i$ by sampling a value from the distribution $P(X_i | \bfx_{-i}^{(t)})$, where $\bfx_{-i}^{(t)} = (x_1^{(t)}, \ldots, x_{i-1}^{(t)}, x_{i+1}^{(t-1)}, \ldots, x_{n}^{(t-1)})$. After $T$ samples are generated, all one-variable marginals can be estimated using the following quantity
\begin{align}\label{eq:gibss}
\widetilde{P}_T(x_i) = \frac{1}{T} \sum_{t=1}^T P(x_i | \bfx_{-i}^{(t)} ).
\end{align}
It could be shown, that in the limit of infinite samples, $\widetilde{P}_T(x_i)$ will converge to $P(x_i)$ if the underlying Markov chain is regular and reversible \cite{venugopal2013giss}.
\end{definition}
In the next example, we show how Gibbs sampling works out on the \textit{Rain-Sprinkler} network.
\begin{example}[Gibbs sampling]
Consider the BN in Figure \ref{rainBN}. Suppose we have the initial state 
\begin{align*}
\bfx^{(0)} = (R^{(0)} = \rT, S^{(0)} = \sF, G^{(0)} = \gT)
\end{align*}
and no evidence is available. For each Gibbs iteration, we resample all unobserved variables, one in a time, in a predetermined order, say $(R, S, G)$. So, we first sample $R^{(1)}$ from the distribution $P(R | S^{(0)} = \sF, G^{(0)} = \gT)$, which could be made explicitly
%\begin{align*}
%P(R = \rT | S^{(0)} = \sT, G^{(0)} = \gT) &= \frac{P(\rT, \sT,  \gT)}{P(\sT, \gT)} = \frac{P(\gT | \rT, \sT) P(\sT | \rT) P(\rT)}{\sum_{\rr \in {\{T,F\}}}P(\rr, \sT, \gT)} \\
%&= \frac{0.99 \cdot 0.01 \cdot 0.2}{0.00198_{\rT, \sT, \gT} + 0.288_{\rF, \sT, \gT}} \approx 0.0068.
%\end{align*}
\begin{align*}
P(R = \rT | S^{(0)} = \sF, G^{(0)} = \gT) &= \frac{P(\rT, \sF,  \gT)}{P(\sT, \gT)} = \frac{0.1584}{0.00198_{\rT, \sT, \gT} + 0.288_{\rF, \sT, \gT}} \approx 0.5462.
\end{align*}
Hence $P(R = \rF | S^{(0)} = \sF, G^{(0)} = \gT) \approx 0.4538$. If we have drawn a value from this distribution, for example $R^{(1)} = \rF$, we continue to resample $S^{(1)}$ from the distribution $P(S | R^{(1)} = \rF, G^{(0)} = \gT)$, obtaining for example $S^{(1)} = \sT$. Finally, we sample $G^{(1)}$ from $P(G | R^{(1)} = \rF, S^{(1)} = \sT)$, resulting in $\gT$. Therefore, the result of the first iteration of Gibbs sampling is the sample $\bfx^{(1)} = (R^{(1)} = \rF, S^{(1)} = \sT, G^{(1)} = \gT)$. This process repeats.
\end{example}
As mentioned before, Gibbs sampling could perform poorly in the presence of deterministic relations \cite{koller2009probabilistic, poon2006sound, gogate2011samplesearch}. In the next example, we give an illustration of this phenomenon.
\begin{example}\label{ex:gibbs}
Consider the BN in Figure \ref{gibbs}. Suppose the initial configuration $\bfx^{(0)} = (A^{(0)} = 0,\ B^{(0)} = 0)$ -- shortened $(0,0)$ -- is given and suppose no evidence is available. 
In the first Gibbs iteration, we resample both unobserved variables, one at a time, in the order $A, B$. Thus, we first sample $A^{(1)}$ from the distribution $P(A | B^{(0)} = 0)$. According to the CPT, with probability $1$ this turns out to be $A=0$. Consecutively, we sample $B^{(1)}$ from the distribution $P(B | A^{(1)} = 0 )$. Which always returns $B = 0$. As a consequence, the Markov chain created by Gibbs sampling behaves like
\begin{align*}\label{gibbs-trap}
(0,0) \to (0,0) \to (0,0) \to \ldots ,
\end{align*}
yielding that $\bfx^{(i)} = (0,0)$ for all $i \geq 0$. Hence, inference based on Gibbs sampling returns $P(A=0) = 1$. The real distribution for $A$ on the other hand must equal $P(A=0) = P(A=1) = 0.5$.
\end{example}
When no deterministic relations are present in a BN, it could be shown \cite{poon2006sound} that Gibbs sampling generates a regular and reversible Markov chain (and therefore converges to the desired posterior distribution). Though, as illustrated in Example \ref{ex:gibbs}, when deterministic dependencies are present in the BN, regularity and reversibility could break down and the estimation given in Equation (\ref{eq:gibss}) could no longer converge to $P(x_i)$. \\
Many solutions have been proposed in the past to address this problem \cite{venugopal2013giss, poon2006sound}. So do we: we devised a MCMC method that always converges to the desired posterior distribution, especially in the presence of deterministic relations.
\begin{center}
\begin{figure}[h!]
\centering
\begin{tikzpicture}[node distance=1.2cm, >=triangle 60]
\node [events] (a) {A};
\node [events,  right=of a] (b) {B};


\draw [->] (a) -- (b);

{\small
\node [left = 1cm of a] (ta) {
    \begin{tabular}{|c||c|} \hline
    	$A=0$ & $0.5$ \\ \hline
    	$A=1$ & $0.5$\\ \hline
    \end{tabular}
    };
    
\node [right = 1cm of b] (tb) {
    \begin{tabular}{|c||c|c|} \hline
	&$A=0$&$ A=1 $  \\ \hline \hline
	$B=0$ & $1$ & $0$ \\ \hline
	$B=1$ & $0$ & $1$ \\ \hline
\end{tabular}
    };}
    
\draw [dotted] (a) -- (ta);
\draw [dotted] (b) -- (tb);
\end{tikzpicture}
\caption{a BN with a deterministic relation. The state of B is equal to the state of A with probability 1.}
\label{gibbs}
\end{figure}
\end{center}

\chapter{Prune Sampling}\label{ch:3}
In Section \ref{sec:mcmc} we looked at MCMC sampling methods and their short comings when deterministic relations appear in a BN. In this chapter we define \psp \Ps is a MCMC sampling method that always converges to the correct posterior distribution, even in the presence of determinism. First, we explain how this technique is inspired by the sound MC-SAT algorithm. Then, we introduce the mathematical notation and -definition of \psp Consecutively, we show theoretically why the \textit{prune} technique always generates a regular and reversible Markov chain with respect to the desired distribution. Ultimately, we elaborate on the practical implementation of the \ps algorithm.

\section{Background: MC-SAT algorithm}
As we concluded Chapter \ref{ch:2}, many solutions have been proposed in the past to address the problem of trapped Gibbs samples. Notable examples are the Sample Search, GiSS algorithm \cite{venugopal2013giss} and the slice sampling method \cite{besag1993spatial, damlen1999gibbs, gilks1996interdisciplinary}. The algorithm MC-SAT \cite{poon2006sound} is a special case of slice sampling and applies the strategy of using auxiliary variables in the more general framework of Markov logic networks (MLNs). Poon and Domingos show that MC-SAT is a sound MCMC algorithm, meaning it generates a Markov chain which is regular and reversible, even in the presence of deterministic relations. \\

To apply MC-SAT on BNs, a translation to a weighted \gls{SAT} is necessary. This has two drawbacks. In the first place, an explicit translation of a BN to a weighted SAT problem is memory intensive. Secondly, the graphical dependencies of BNs are lost when the BN structure is translated to a SAT problem. In order not to suffer from these drawbacks, we bring the key strenghts of the MC-SAT algorithm -- the construction of a random sample space --  to the field of BNs. In doing so, it keeps using the compact and graphical structure of BNs. To be able to share these concepts in the best possible way, we first introduce the mathematical notation and -definition of \psp

\section{Notation and definition}
The key idea of \ps is straight-forward: since the exhaustive listing of all feasible states of the original BN is impossible (as described in Section \ref{sec:inference}, due to too much memory and time consumption), the exhaustive listing of all solutions of a randomly pruned BN is possible. In order to describe this concept properly, we introduce the following notation. \\

Given a BN structure $\G$ with $n$ variables and corresponding CPTs. For $i = 1, \ldots , n$, let $l_i$ be the label of the entries in the CPT of variable $X_i$, so $1 \leq \gls{l_i} \leq | Val(X_i) | \cdot | Val(\text{Pa}_{X_i})|$. Then, we denote 
\begin{align}
\begin{split}
\gls{C} := \{ & \gls{kli} : \gls{c_k_l_i} \text{ is an entry in the CPT of variable $X_i$, for $1 \leq i \leq n$} \}
\end{split}
\end{align}
as the collection of all CPT-labels of $\G$. Here, $\gls{k}$ is an abbreviation of the name of node $X_i$. For convenience, this notation is applied on the simple deterministic BN we saw before.
\begin{example} The collection of CPT-labels $\C$ of the BN in Figure \ref{gibbs} contains 6 labels: 2 for the CPT of node $A$ -- indexed by $A(1), A(2)$ -- and 4 for the CPT of node $B$ -- indexed by $B(1), B(2), B(3), B(4)$. For completeness, $\C = \{ A(1), A(2), B(1), B(2), B(3), B(4) \}$.
\end{example}
A state $\bfx$ of the BN corresponds to a unique collection of $n$ CPT-values $c_{ k(l)}$. We denote the collection of CPT-labels $k(l)$, corresponding to these values by $\gls{Cx}$. Accordingly, the state $(A = 0, B = 0)$ of the BN presented in Figure \ref{gibbs} corresponds to $\C_\bfx = \{ A(1), B(1) \}$. In general, observe that 
\begin{align*}
P(\bfx) = \prod_{k(l) \in \C_\bfx} c_{ k(l)}.
\end{align*}
\begin{figure}[t!]
\centering
\begin{adjustbox}{width=\textwidth}
\begin{tikzpicture}[node distance=1.2cm, >= triangle 60]

\node [events] (kidney) {Kidney};
\node [events, below right=of kidney] (bp) {BloodPres.};
\node [events, above right=of bp] (lifestyle) {Lifestyle};
\node [events, below=of bp] (measure) {Measurement};
\node [events, below right=of lifestyle] (sports) {Sports};


\draw [->] (kidney) -- (bp);
\draw [->] (lifestyle) -- (bp);
\draw [->] (lifestyle) -- (sports);
\draw [->] (bp) -- (measure);

{\small
\node [left = 1cm of kidney] (t_k) {
    \begin{tabular}{|c||c|} \hline
    	$k_b$ & $\cancel{0.5}$\\ \hline
    	$\mathbf{k_g}$ & $\mathbf{0.5}$ \\ \hline
    \end{tabular}
    };
    
\node [right = 1cm of lifestyle] (t_l) {
\begin{tabular}{|c||c|} \hline
	$\mathbf{l_b}$ & $\mathbf{0.5}$\\ \hline
	$l_g$ & $0.5$ \\ \hline
\end{tabular}
};
    
\node [left = 1cm of bp] (t_bp) {
    \begin{tabular}{|c||c|c|c|c|} \hline
	&$k_b, l_b$ & $ k_b, l_g $ &$ \mathbf{k_g, l_b}$ & $ k_g, l_g $  \\ \hline \hline
	$b_n$ & $\cancel{0.1}$ & $\cancel{0.2}$ & $\cancel{0.2}$ & $0.9$  \\ \hline
	$\mathbf{b_e}$ & $0.9$ & $0.8$ & $\mathbf{0.8}$ & $\cancel{0.1}$ \\ \hline
\end{tabular}};

\node [right = 0.6cm of sports] (t_s) {
    \begin{tabular}{|c||c|c|} \hline
	&$\mathbf{l_b}$&$ l_g $  \\ \hline \hline
	$s_n$ & $0.8$ & $\cancel{0.2}$  \\ \hline
	$\mathbf{s_y}$ & $\mathbf{0.2}$ & $\cancel{0.8}$ \\ \hline
\end{tabular}};

\node [right = 1cm of measure] (t_m) {
    \begin{tabular}{|c||c|c|} \hline
	&$b_n$&$ \mathbf{b_e} $  \\ \hline \hline
	$m_n$ & $0.9$ & $\cancel{0.1}$  \\ \hline
	$\mathbf{m_e}$ & $\cancel{0.1}$ & $\mathbf{0.9}$ \\ \hline
\end{tabular}}

;}
    
\draw [dotted] (kidney) -- (t_k);
\draw [dotted] (lifestyle) -- (t_l);
\draw [dotted] (bp) -- (t_bp);
\draw [dotted] (sports) -- (t_s);
\draw [dotted] (measure) -- (t_m);
\end{tikzpicture}
\end{adjustbox}
\caption{a pruned version of the BloodPressure network around the boldfaced initial state $\bfx = (k_g, l_b, b_e, s_y, m_e)$. Note that the lower the value of the CPT-entry, the higher the probability that the index gets pruned. We see that $S_{\C_\bfx^{\text{np}}}$ contains two feasible states, i.e. $(k_g, l_b, b_e, s_y, m_e)$ and $(k_g, l_b, b_e, s_n, m_e)$.}
\label{pruning}
\end{figure}
In addition, let $\gls{textC}$ be an arbitrary collection of CPT-labels. We denote the set of possible (not necessarily feasible) states that correspond to these CPT-labels by $\gls{S_C}$. The definition of a feasible state is given below.
\begin{definition}[Feasible state]
A feasible state of the BN is a state $\bfx$ such that $P(\bfx)>0$, i.e. each unique CPT-value corresponding to state $\bfx$ is positive.
\end{definition}
Having introduced this notation and definitions, we are ready to define the concept of \textit{pruning}.
\begin{definition}[Pruning around state $\bfx$]\label{prunedef}
Let $\gls{Cxp}$ be the subset of $\C$ that is constructed by adding each CPT-index $k(l) \in \C \setminus \C_{\bfx}$ with probability $1-c_{k(l)}$ to the set $\C_\bfx^{\text{p}}$ and with probability $c_{k(l)}$ not. We say that the collection $\C_\bfx^{\text{p}}$ contains the pruned CPT-indices. 
\end{definition}
The next example gives an illustration of the \textit{pruning} technique on the BloodPressure BN.
\begin{example}\label{ex:pruning}
Consider the BN in Figure \ref{pruning}. Pruning around the boldfaced initial state $\bfx = (k_g, l_b, b_e, s_y, m_e)$ could yield the non-crossed indices 
\begin{align*}
\C_\bfx^{\text{p}} = \{ K(2), L(2), BP(4), BP(5), BP(6), S(1), M(1) \}.
\end{align*}
Note that the lower the value of the CPT-entry, the higher the probability that the index gets pruned. 
\end{example}
The collection of CPT-indices that do not get pruned is given by $\gls{Cxnp}:=\C \setminus \C_\bfx^{\text{p}}$. In the situation of Example \ref{ex:pruning}, $S_{\C_\bfx^{\text{np}}}$ exist of two feasible states, i.e. $(k_g, l_b, b_e, s_y, m_e)$ and $(k_g, l_b, b_e, s_n, m_e)$. Having introduced these concepts, one should note three things
\begin{enumerate}
\item $\C_\bfx^{\text{p}}$ is a random set;
\item $\C_\bfx \subset \C_\bfx^{\text{np}} \text{ and } \bfx \in S_{\C_\bfx^{\text{np}}}$;
\item the probability of generating $\C_\bfx^{\text{p}}$ and $\C_\bfx^{\text{np}}$ is given by
\begin{align*}
\prod_{k(l) \in \C_\bfx^{\text{p}}}(1-c_{k(l)}) \cdot \prod_{k(l) \in \C_\bfx^{\text{np}} \setminus \C_{\bfx}} c_{k(l)}.
\end{align*}
%\item $\C_{\bfx^{(i-1)},n}$ contains all the non-zero indices in $\C$, implying that $S_{\C_{\bfx^{(i-1)},n}}$ contains all feasible states of the BN, with strictly positive probability.
\end{enumerate}
Due to the pruning of CPT-entries in the original BN, the number of feasible states in the pruned BN is much smaller in comparison to the number of feasible states in the original BN. This significant decrease of the number of feasible states, can make \ps practically applicable. Assuming we have sufficient memory, a breath first search approach can be used to list all feasible states of the pruned BN. From this collection we can easily draw a state uniformly.

\begin{definition}[Uniform sampling over a set of states]
As defined before, $S_{\C_\bfx^{\text{np}}}$ is the set of (feasible) states corresponding to the CPT-indices which are not pruned. We define $\gls{U}$
as the uniform distribution over the states in $S_{\C_\bfx^{\text{np}}}$ and we write
\begin{align*}
\U(S_{\C_\bfx^{\text{np}}})(\bfy) = \frac{1}{|S_{\C_\bfx^{\text{np}}}|}
\end{align*}
for the probability of sampling state $\bfy$ with respect to this uniform distribution.
\end{definition}
Doing these steps -- pruning, uniform sampling, updating the sample space --  gives us a sequence of samples that is able to visit the whole state space. We call this proces \ps, the pseudo-code could be found in Algorithm \ref{prunealg}. The algorithm takes as input a BN structure $\G$ with corresponding CPTs, an initial configuration $\bfx$ and the integer $T$ for the number of samples to be generated. The algorithm begins with an initial state $\bfx^{(0)}$. For $t = 1, \ldots , T$ it then prunes around $\bfx^{(t-1)}$ to obtain $\C_{\bfx^{(t-1)}}^{\text{np}}$ and to consecutively sample $\bfx^{(t)}$ from $\U(S_{\C_\bfx^{\text{np}}})$. Finally, the algorithm updates the new configuration $S$ of the BN.  \\

Note that with strictly positive probability $\C_{\bfx^{(t-1)}}^{\text{np}}$ contains all the non-zero indices in $\C$, implying that $S_{\C_{\bfx^{(t-1)}}^{\text{np}}}$ contains all feasible states of the BN. This means that \ps generates a regular Markov chain, i.e. with positive probability a state $\bfx$ can transition to any other feasible state $\bfy$ in one step. The reversibility conditions takes more effort to show and is addressed in the next section. 
\begin{algorithm}[h!]
\renewcommand\thealgorithm{1}
\caption{Prune sampling algorithm}
\label{prunealg}
\begin{algorithmic}
%\Require{We can prune a BN given a state $\mathbf{x}$}
\Function{PruneSampling}{BN, initial, T}
\State $\mathbf{x}^{(0)} \gets $ initial
     \State $\mathcal{S} \gets \{\mathbf{x}^{(0)}\}$
     \For{$t \gets 1 $ to$ $ T}
     \State $\C_{\bfx^{(t-1)}}^{\text{p}} \gets \text{Prune around } \mathbf{x}^{(t-1)}$ \\ \Comment{{\footnotesize See Definition $3.2$ }}
	\State $\C_{\bfx^{(t-1)}}^{\text{np}} \gets \mathcal{C} \setminus \C_\bfx^{\text{p}}$  
     \State $\mathbf{x}^{(t)} \sim  \U(S_{\C_\bfx^{\text{np}}}) $ 
     \State $\mathcal{S} \gets \mathcal{S} \cup \mathbf{x}^{(t)}$
     \EndFor
     \State \Return{$\mathcal{S}$}
\EndFunction
\end{algorithmic}
\end{algorithm}

\subsection{Regularity and reversibility}
To make a transition from a state $\bfx$ to a state $\bfy$ we need to prune around $\bfx$ such that non of the indices corresponding to $\bfy$ is pruned. This leads to the following definition. 

\begin{definition}[Pruning around state $\bfx$ and $\bfy$]
Let $\gls{Cpxy}$ be the subset of $\mathcal{C}$ that is constructed by pruning around $\mathbf{x}$ or pruning around $\mathbf{y}$ such that none of the indices corresponding to $\mathbf{x}$ and non of the indices corresponding to $\mathbf{y}$ is contained in $\mathcal{C}_{\{\mathbf{x}, \mathbf{y}\}}^{\text{p}}$.
\end{definition}
Note that the collection of CPT-indices that do not get pruned is given by $\gls{Cnpxy} := \C \setminus \mathcal{C}_{\{\mathbf{x}, \mathbf{y}\}}^{\text{p}}$. For each two states $\bfx$ and $\bfy$ there are finitely many ways, $\gls{H}$, to create a pruned collection $\gls{Cpxyh}$ and a non-pruned collection $\gls{Cnpxyh}$, where $h =1,\ldots, H$, such that $\bfx$ can make a transition to $\bfy$ by sampling from $\U(S_{\C_{\{\bfx, \bfy\},h}^{\text{np}}})$. For $h =1, \ldots, H$ we define the transition probabilities from $\bfx$ to $\bfy$ by pruning a certain collection by
\begin{align}\label{transprob}
\gls{Rhxy} &:= \left(\prod_{k(l) \in \C_{\{\bfx, \bfy\},h}^{\text{p}} } (1-c_{k(l)}) \right) \cdot \left( \prod_{k(l) \in \C_{\{\bfx, \bfy\},h}^{\text{np}} \setminus \mathcal{C}_{\mathbf{x}}  } c_{k(l)}   \right) \cdot \mathcal{U} \big( S_{\C_{\{\bfx, \bfy\},h}^{\text{np}}} \big)(\mathbf{y}) \\ \nonumber
&\;=\left(\prod_{k(l) \in \C_{\{\bfx, \bfy\},h}^{\text{p}} } (1-c_{k(l)}) \right)\cdot \left( \prod_{k(l) \in \C_{\{\bfx, \bfy\},h}^{\text{np}} \setminus \mathcal{C}_{\mathbf{x}}  } c_{k(l)}   \right)  \nonumber \cdot \frac{1}{|S_{\C_{\{\bfx, \bfy\},h}^{\text{np}}}|}.
\end{align}
In words, Equation (\ref{transprob}) expresses the probability of pruning certain CPT-indices around $\bfx$, such that none of the CPT-indices corresponding to $\bfy$ is pruned, and subsequently sampling $\bfy$ uniformly from the states corresponding to the CPT-indices that were not pruned. The total probability of transitioning from $\bfx$ to $\bfy$ is therefore given by
\begin{align} \label{total}
{R}(\mathbf{x} \to \mathbf{y}) = \sum_{h=1}^{H} {R}_h (\mathbf{x} \to \mathbf{y}).
\end{align}
To show reversibility we need to show that the transition probability satisfies the detailed balance equation
\begin{align*}
P(\mathbf{x}) R(\mathbf{x} \to \mathbf{y}) = P(\mathbf{y}) R(\mathbf{y} \to \mathbf{x}) 
\end{align*}
which equals
\begin{align*}
P(\mathbf{x}) \left(\sum_{h=1}^{H} {R}_h (\mathbf{x} \to \mathbf{y}) \right) = P(\mathbf{y}) \left(\sum_{h=1}^{H} {R}_h (\mathbf{y} \to \mathbf{x}) \right).
\end{align*}
So, it is sufficient to show that
\begin{align} \label{toshow}
P(\mathbf{x}) {R}_h (\mathbf{x} \to \mathbf{y}) = P(\mathbf{y})  {R}_h (\mathbf{y} \to \mathbf{x}), 
\end{align}
for $h = 1, \ldots, H$. The following computation shows that Equation \eqref{toshow} holds
\begin{align*}
&P(\mathbf{x}) {R}_h (\mathbf{x} \to \mathbf{y}) \\
&= \frac{1}{Z} \cdot P(\mathbf{x}) \cdot \left(\prod_{k(l) \in \C_{\{\bfx, \bfy\},h}^{\text{p}} } (1-c_{k(l)}) \right)\cdot \left( \prod_{k(l) \in \C_{\{\bfx, \bfy\},h}^{\text{np}}  \setminus \mathcal{C}_{\mathbf{x}} } c_{k(l)} \right) \\ 
&= \frac{1}{Z} \cdot \prod_{k(l) \in \mathcal{C}_{\mathbf{x}}} c_{k(l)} \cdot \left(\prod_{k(l) \in \C_{\{\bfx, \bfy\},h}^{\text{p}} } (1-c_{k(l)}) \right)\cdot \left( \prod_{k(l) \in \C_{\{\bfx, \bfy\},h}^{\text{np}} \setminus \mathcal{C}_{\mathbf{x}} } c_{k(l)} \right) \\ 
&= \frac{1}{Z} \cdot \left(\prod_{k(l) \in \C_{\{\bfx, \bfy\},h}^{\text{p}}} (1-c_{k(l)}) \right)\cdot \left( \prod_{k(l) \in \C_{\{\bfx, \bfy\},h}^{\text{np}}   } c_{k(l)}   \right) \\ 
&= \frac{1}{Z} \cdot \left(\prod_{k(l) \in \C_{\{\bfx, \bfy\},h}^{\text{p}}} (1-c_{k(l)}) \right)\cdot \left( \prod_{k(l) \in \mathcal{C}_{\mathbf{y}}} c_{k(l)}   \right) \cdot  \prod_{k(l) \in \C_{\{\bfx, \bfy\},h}^{\text{np}} \setminus \mathcal{C}_{\mathbf{y}}  } c_{k(l)} \\ 
&= \frac{1}{Z} \cdot \left(\prod_{k(l) \in \C_{\{\bfx, \bfy\},h}^{\text{p}} } (1-c_{k(l)}) \right)\cdot P(\mathbf{y}) \cdot\left( \prod_{k(l) \in \C_{\{\bfx, \bfy\},h}^{\text{np}}  \setminus \mathcal{C}_{\mathbf{y}}  } c_{k(l)}   \right) \\ 
&= P(\mathbf{y}) {R}_h (\mathbf{y} \to \mathbf{x}),
\end{align*}
\noindent where $Z = |S_{\C_{\{\bfx, \bfy\},h}^{\text{np}} }|$. We conclude that \ps generates a regular and a reversible Markov chain with respect to the desired distribution $P$. As discussed before, we therefore know that $P$ is the unique stationary distribution of the Markov chain generated by \textit{prune sampling}.


\section{Practical implementation}
The implementation of the pruning technique requires two non-trivial steps: to generate an initial state of the BN and to sample uniformly over the pruned BN. We explain how we met these requirements in this first version of \ps and explain how the MC-SAT algorithm deals with these questions.
\subsection{Generate initial states}
\subsection{Sampling from the pruned network}

\chapter{Results}

\section{Simple deterministic network}

\begin{figure}[h]
\centering
\begin{subfigure}{.49\textwidth}
  \centering
  \includegraphics[width=\linewidth]{/Users/jurriaan/Documents/LaTeX/MSc_thesis_UU/Paper_Prune_Sampling/simple_det_250_samples.png}
  \caption{250 samples prune vs Gibbs}
  \label{fig:sub1}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
  \centering
  \includegraphics[width=\linewidth]{/Users/jurriaan/Documents/LaTeX/MSc_thesis_UU/Paper_Prune_Sampling/simple_det_10000_samples.png}
  \caption{10.000 samples prune vs Gibbs}
  \label{fig:sub2}
\end{subfigure}
\caption{illustration of superior performance of \ps. Due to the deterministic relation in the BN given in Example \ref{ex:gibbs}, Gibbs sampling is trapped in the chain $(0,0)$ or $(1,1)$. Hence, doing inference on these Gibbs samples yield $P(A = 0)=0$ or $P(A = 0)=1$ (red and green line). As a consequence of the regular and reversible Markov chain generated by \ps (blue and orange line), this Markov chain is able to move around the entire state space and therefore converges to the correct probability distribution $P(A = 0) = 0.5$.}
\label{simple-deterministic}
\end{figure}

\newpage
\subsection{Block shaped network}

\begin{figure}[h]
\centering
\begin{subfigure}{.49\textwidth}
  \centering
  \includegraphics[width=\linewidth]{/Users/jurriaan/Documents/LaTeX/MSc_thesis_UU/Paper_Prune_Sampling/gibbs_trap_2_gibbs_vs_2_prune_50_samples.png}
  \caption{50 samples prune vs Gibbs}
  \label{fig:sub1}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
  \centering
  \includegraphics[width=\linewidth]{/Users/jurriaan/Documents/LaTeX/MSc_thesis_UU/Paper_Prune_Sampling/gibbs_trap_2_gibbs_vs_2_prune_10000_samples.png}
  \caption{10.000 samples prune vs Gibbs}
  \label{fig:sub2}
\end{subfigure}
\vspace{0.75pc}
\caption{\ps could be superior to Gibbs sampling, even in the absence of deterministic relations. A non-deterministic block shaped CPT -- as presented in Table \ref{block} -- can prevent a Markov chain generated by Gibbs sampling of visiting the entire state space. In this example, being trapped in the subset $\{0, 1\}$ or $\{2, 3\}$ both yield the probability $0.5$ of assigning $0,1$ respectively $2,3$ to variable $X_i$ (red and green line). \textit{Prune sampling} generates a Markov chain that is regular and reversible and therefore can move around freely through the whole state space. Hence converging to the uniformly probability $0.25$ of assigning value $0,1,2$ or $3$ to variable $X_i$ (blue and orange line).} 
\label{block-BN}
\end{figure}

\vspace{2pc}
$P(X_i |X_{i-1})=$
\begin{table}[h!]
\centering
\resizebox{0.5\columnwidth}{!}{
\begin{tabular}{|c||c|c|c|c|} \hline
	&$X_{i-1}=0$ & $ X_{i-1}=1 $ & $X_{i-1}=2$ & $X_{i-1}=3$  \\ \hline \hline
	$X_i =0$ & $0.5$ & $0.5$ & $0$ & $0$ \\ \hline
	$X_i =1$ & $0.5$ & $0.5$ & $0$ & $0$ \\ \hline
	$X_i =2$ & $0$ & $0$ & $0.5$ & $0.5$ \\ \hline
	$X_i =3$ & $0$ & $0$ & $0.5$ & $0.5$ \\ \hline
\end{tabular}
}.
\caption{a block shaped CPT}
\label{block}
\end{table}

\section{Benchmark Bayesian networks}
\subsection{Accuracy}
\subsubsection{Real world Bayesian networks 0\% determinism}\label{real_world_no_evidence}

\begin{figure}[H]
\centering
\begin{subfigure}{0.5\textwidth}
\includegraphics[width = \textwidth]{/Users/jurriaan/Documents/LaTeX/MSc_thesis_UU/Paper_Prune_Sampling/asia_ahd_25000.png}
\caption{Asia 0\% evidence}%
\label{asia}%
\end{subfigure}\hfill%
\begin{subfigure}{0.5\textwidth}
\includegraphics[width = \textwidth]{/Users/jurriaan/Documents/LaTeX/MSc_thesis_UU/Paper_Prune_Sampling/alarm_ahd_25000.png}
\caption{Alarm 0\% evidence}%
\label{alarm}%
\end{subfigure}%
\begin{subfigure}{0.5\textwidth}
\includegraphics[width = \textwidth]{/Users/jurriaan/Documents/LaTeX/MSc_thesis_UU/Paper_Prune_Sampling/win95pts_ahd_25000.png}
\caption{Win95pts 0\% evidence}%
\label{win95pts}%
\end{subfigure}\hfill%
\vspace{0.75pc}
\caption{underperformance of \ps in terms of accuracy on the benchmark real world BNs without evidence. Since no evidence is available, 0\% of the nodes contain deterministic relations. Because \ps is created to deal with determinism, we did expected underperformance of the pruning technique on these type of networks.  }
\label{results2}
\end{figure}

\newpage
\subsubsection{Real world Bayesian networks 25\% determinism}

\begin{figure}[H]
\centering
\begin{subfigure}{0.5\textwidth}
\includegraphics[width = \textwidth]{/Users/jurriaan/Documents/LaTeX/MSc_thesis_UU/Paper_Prune_Sampling/asia_ev_ahd_25000.png}
\caption{Asia 25\% evidence}%
\label{asia}%
\end{subfigure}\hfill%
\begin{subfigure}{0.5\textwidth}
\includegraphics[width = \textwidth]{/Users/jurriaan/Documents/LaTeX/MSc_thesis_UU/Paper_Prune_Sampling/alarm_ev_ahd_25000.png}
\caption{Alarm 25\% evidence}%
\label{alarm}%
\end{subfigure}%
\begin{subfigure}{0.5\textwidth}
\includegraphics[width = \textwidth]{/Users/jurriaan/Documents/LaTeX/MSc_thesis_UU/Paper_Prune_Sampling/win95pts_ev_ahd_25000.png}
\caption{Win95pts 25\% evidence}%
\label{win95pts}%
\end{subfigure}\hfill%
\vspace{0.75pc}
\caption{compared with the results in section \ref{real_world_no_evidence}, \ps starts to become more competitive in terms of accuracy as more determinism is present in the BNs. In these real world BNs 25\% of the nodes contain deterministic relations (evidence). Though, on the win95pts BN \ps underperforms significantly.}
\label{results2}
\end{figure}

\newpage
\subsubsection{Grid Bayesian networks 50\% determinism}
\begin{figure}[H]
\centering
\begin{subfigure}{0.49\textwidth}
\includegraphics[width = \textwidth]{/Users/jurriaan/Documents/LaTeX/MSc_thesis_UU/Paper_Prune_Sampling/grid_3x3_ahd_25000.png}
\caption{Grid 3x3 network 50\% evidence}%
\label{grid_3x3}%
\end{subfigure}\hfill%
\begin{subfigure}{0.49\textwidth}
\includegraphics[width = \textwidth]{/Users/jurriaan/Documents/LaTeX/MSc_thesis_UU/Paper_Prune_Sampling/grid_5x5_ahd_25000.png}
\caption{Grid 5x5 network 50\% evidence}%
\label{grid_5x5}%
\end{subfigure}
\begin{subfigure}{0.49\textwidth}
\includegraphics[width = \textwidth]{/Users/jurriaan/Documents/LaTeX/MSc_thesis_UU/Paper_Prune_Sampling/grid_8x8_ahd_25000.png}
\caption{Grid 8x8 network 50\% evidence}%
\label{grid_8x8}%
\end{subfigure}\hfill%
\caption{underperformance of \ps in terms of accuracy on the benchmark grid BNs. 50\% of the nodes in these Grid networks are deterministic. Since \ps is created to deal with determinism, we did expect that pruning would perform much better on these type of networks. In this case, Gibbs and Metropolis sampling do converge to the correct posterior distribution. Note that this is not always true.}
\label{results1}
\end{figure}


\subsection{Rate of convergence}

\begin{figure}[H]
\centering
\begin{subfigure}[t]{0.5\textwidth}
  \centering
  \captionsetup{width = 0.9\textwidth}
  \includegraphics[width = \textwidth]{/Users/jurriaan/Documents/LaTeX/MSc_thesis_UU/Paper_Prune_Sampling/1.png}
  \caption{In the Grid $8 \times 8$ BN, a bunch of $100$ Metropolis runs of $25.000$ samples approximate the one-variable marginal $P(X 8\_8 = T) \approx 0.81$.}
  \label{sub_a}
\end{subfigure}%
\begin{subfigure}[t]{0.5\textwidth}
  \centering
  \captionsetup{width = 0.9\textwidth}
  \includegraphics[width = \textwidth]{/Users/jurriaan/Documents/LaTeX/MSc_thesis_UU/Paper_Prune_Sampling/2.png}
  \caption{According to convergence class $\mathcal{O}(t^{-1/2})$, the standard deviation ${\sigma}^2(t)$ of the $100$ Metropolis runs decreases with the number of samples $t$ with rate $t^{-1/2}$.}
  \label{sub_b}
\end{subfigure}

\begin{subfigure}[t]{0.5\textwidth}
  \centering
  \captionsetup{width = 0.9\textwidth}
  \includegraphics[width = \textwidth]{/Users/jurriaan/Documents/LaTeX/MSc_thesis_UU/Paper_Prune_Sampling/3.png}
  \caption{Plotting the $\log$ of the standard deviation -- $\log {\sigma}^2(t)$ -- versus the $\log$ of the number of points -- $\log t$ -- helps us to estimate the proportionality constant $\alpha$ in $\frac{\alpha}{\sqrt{t}}$. In this plot we have estimated $\alpha = 0.4$.}
  \label{sub_c}
\end{subfigure}%
\begin{subfigure}[t]{0.5\textwidth}
  \centering
  \captionsetup{width = 0.9\textwidth}
  \includegraphics[width = \textwidth]{/Users/jurriaan/Documents/LaTeX/MSc_thesis_UU/Paper_Prune_Sampling/4.png}
  \caption{To determine $\alpha$ based on its asymptotic behavior as $\alpha / \sqrt{t}$, we want to ignore the interval $10^0$ - $10^1$ in Figure \ref{sub_c}. In doing so, we introduce a polynomial expansion to approximate the linear log plot as $\alpha(1+\beta t^{-\delta})$. Fitting this function to the blue line in the above figure, we retrieve that $\alpha \approx 0.4$. }
  \label{sub_d}
\end{subfigure}
\caption{procedure to determine the proportionality constant of the sampling methods.}
\label{determine-c}
\end{figure}

\begin{center}
\begin{table}[H]
\begin{center}
\begin{tabular}{l c c c}  
\toprule
\multicolumn{4}{r}{Sampling method} \\
\cmidrule(r){2-4}
Bayesian \\ network    & Gibbs    & Metropolis & Prune  \\
\midrule
Asia\_ev0 & 0.52 & \textbf{0.51} & 0.81  \\
Alarm\_ev0 & \textbf{0.43} & 0.46 & 0.79  \\
Win95pts\_ev0 & \textbf{0.48} & 0.55 & 0.59  \\
Asia\_ev25 & 0.47 & \textbf{0.45} & 0.77  \\
Alarm\_ev25 & 0.40 & \textbf{0.37} & 0.49  \\
Win95pts\_ev25 & \textbf{0.45} & 0.48 & 0.50  \\
%SAM_vAN & 0.40 & 0.45 & 0.56  \\
Grid 3x3 & \textbf{0.37} & 0.38 & 0.62  \\
Grid 5x5 & 0.54 & \textbf{0.49} & 0.55  \\
Grid 8x8 & \textbf{0.39} & 0.40 & 0.53  \\
%Grid 11x11 & 0.45 & 0.45 & x \\
\bottomrule
\end{tabular}
\caption{the proportionality constants of \ps are always higher than Gibbs- and Metropolis sampling. Hence, samples generated by \ps converge slower to the desired distribution.}
\label{ROC-table}
\end{center}
\end{table}
\end{center}

\subsection{Time consumption}

\begin{center}
\begin{table}[!htb]
\begin{center}
\begin{tabular}{l c c c}  
\toprule
\multicolumn{4}{r}{Sampling method} \\
\cmidrule(r){2-4}
Bayesian \\ network    & Gibbs    & Metropolis & Prune  \\
\midrule
Asia\_ev0 & 2.72 & 1.31 & \textbf{0.53}  \\
Alarm\_ev0 & 12.27 & 3.94 & \textbf{3.56}  \\
Win95pts\_ev0 & 36.38 & \textbf{21.32} & 49.85  \\
Asia\_ev25 & 2.56 & 1.05 & \textbf{0.41}  \\
Alarm\_ev25 & 9.92 & 3.07 & \textbf{2.83}  \\
Win95pts\_ev25 & 29.65 & \textbf{16.03} & 40.03  \\
Grid 3x3 & 1.67 & 1.76 & \textbf{0.73}  \\
Grid 5x5 & 12.13 & 4.70 & \textbf{2.42}  \\
Grid 8x8 & 20.50 & \textbf{8.83} & 105.17  \\
\bottomrule
\end{tabular}
\caption{time consumption of the sampling methods. \Ps is the fastest on small and medium sized network. Metropolis performs better on the large sized networks. }
\label{ROC-table}
\end{center}
\end{table}
\end{center}

%\section{Measures of complexity}
%\subsection{d-seperation}
%\subsection{Treewidth}
%\subsection{Junction tree algorithm}
%
%
%\chapter{Improvement of prune sampling}
%\section{Logic sampling}
%\section{Simulated annealing}
\chapter{Improvement of prune sampling}
\section{Uniformly sampling}
\begin{figure*}[h!]
\centering
\captionsetup[subfigure]{justification=centering}

\begin{subfigure}{.3\linewidth}
\includegraphics[width=1.2\columnwidth]{/Users/jurriaan/Documents/MScWiskunde/20180907_TNOdrive/Bayesian_network_repository/xdsl-benchmark-GeNIe-files/Asia/Prune/asia_hist_num_samples.png}
\caption{Asia 0\% determinism, max set size $16$}%
\label{asia_ev}%
\end{subfigure}\hfill%
\begin{subfigure}{.3\linewidth}
\includegraphics[width=1.2\columnwidth]{/Users/jurriaan/Documents/MScWiskunde/20180907_TNOdrive/Bayesian_network_repository/xdsl-benchmark-GeNIe-files/Alarm/Prune/alarm_hist_num_samples.png}
\caption{Alarm 0\% determinism, max set size $2.218$}%
\label{alarm_ev}%
\end{subfigure}\hfill%
\begin{subfigure}{.3\linewidth}
\includegraphics[width=1.2\columnwidth]{/Users/jurriaan/Documents/MScWiskunde/20180907_TNOdrive/Bayesian_network_repository/xdsl-benchmark-GeNIe-files/Win95pts/Prune/win95pts_hist_num_samples.png}
\caption{Win95pts 0\% determinism, max set size $34.125$}%
\label{win95pts_ev}%
\end{subfigure}\hfill%

\begin{subfigure}{.3\linewidth}
\includegraphics[width=1.2\columnwidth]{/Users/jurriaan/Documents/MScWiskunde/20180907_TNOdrive/Bayesian_network_repository/xdsl-benchmark-GeNIe-files/Asia_ev25/Prune/asia_ev_hist_num_samples.png}
\caption{Asia 25\% determinism, max set size $8$}%
\label{asia_ev}%
\end{subfigure}\hfill%
\begin{subfigure}{.3\linewidth}
\includegraphics[width=1.2\columnwidth]{/Users/jurriaan/Documents/MScWiskunde/20180907_TNOdrive/Bayesian_network_repository/xdsl-benchmark-GeNIe-files/Alarm_ev25/Prune/alarm_ev_hist_num_samples.png}
\caption{Alarm 25\% determinism, max set size $505$}%
\label{alarm_ev}%
\end{subfigure}\hfill%
\begin{subfigure}{.3\linewidth}
\includegraphics[width=1.2\columnwidth]{/Users/jurriaan/Documents/MScWiskunde/20180907_TNOdrive/Bayesian_network_repository/xdsl-benchmark-GeNIe-files/Win95pts_ev25/Prune/win95pts_ev_hist_num_samples.png}
\caption{Win95pts 25\% determinism, max set size $2.662$}%
\label{win95pts_ev}%
\end{subfigure}\hfill%

\begin{subfigure}{.3\linewidth}
\includegraphics[width=1.2\columnwidth]{/Users/jurriaan/Documents/MScWiskunde/20180907_TNOdrive/Bayesian_network_repository/xdsl-benchmark-GeNIe-files/Grid_3x3/Prune/grid_3x3_hist_num_samples.png}
\caption{Grid 3x3 50\% evidence, max set size $14$}%
\label{grid_3x3}%
\end{subfigure}\hfill%
\begin{subfigure}{.3\linewidth}
\includegraphics[width=1.2\columnwidth]{/Users/jurriaan/Documents/MScWiskunde/20180907_TNOdrive/Bayesian_network_repository/xdsl-benchmark-GeNIe-files/Grid_5x5/Prune/grid_5x5_hist_num_samples.png}
\caption{Grid 5x5 50\% evidence, max set size $130$}%
\label{grid_5x5}%
\end{subfigure}\hfill%
\begin{subfigure}{.3\linewidth}
\includegraphics[width=1.2\columnwidth]{/Users/jurriaan/Documents/MScWiskunde/20180907_TNOdrive/Bayesian_network_repository/xdsl-benchmark-GeNIe-files/Grid_8x8/Prune/grid_8x8_hist_num_samples.png}
\caption{Grid 8x8 50\% evidence, max set size $8.157$}%
\label{grid_8x8}%
\end{subfigure}\hfill%

\vspace{0.75pc}
\caption{histogram of the number of feasible states in the pruned network. As the size of the BNs (nodes and parameters) increases, the number of feasible states increases. Therefore, exhaustive listing of all feasible states becomes time intensive for large BNs.}
\label{results1}
\end{figure*}

\newpage
\section{Hybrid forward sampling}
\begin{figure*}[h!]
\centering

\begin{subfigure}{.5\linewidth}
\includegraphics[height=5.3cm]{/Users/jurriaan/Documents/MScWiskunde/20180907_TNOdrive/Bayesian_network_repository/xdsl-benchmark-GeNIe-files/Alarm/alarm_ahd4_25000.png}
\caption{Alarm 0\% determinism}%
\label{alarm_ev}%
\end{subfigure}\hfill%
\begin{subfigure}{.5\linewidth}
\includegraphics[height=5.3cm]{/Users/jurriaan/Documents/MScWiskunde/20180907_TNOdrive/Bayesian_network_repository/xdsl-benchmark-GeNIe-files/Win95pts/win95pts_ahd4_25000.png}
\caption{Win95pts 0\% determinism}%
\label{win95pts_ev}%
\end{subfigure}

\begin{subfigure}{.5\linewidth}
\includegraphics[height=5.3cm]{/Users/jurriaan/Documents/MScWiskunde/20180907_TNOdrive/Bayesian_network_repository/xdsl-benchmark-GeNIe-files/Alarm_ev25/alarm_ev_ahd4_25000.png}
\caption{Alarm 25\% determinism}%
\label{grid_3x3}%
\end{subfigure}\hfill%
\begin{subfigure}{.5\linewidth}
\includegraphics[height=5.3cm]{/Users/jurriaan/Documents/MScWiskunde/20180907_TNOdrive/Bayesian_network_repository/xdsl-benchmark-GeNIe-files/Win95pts_ev25/win95pts_ev_ahd7_25000.png}
\caption{Win95pts 25\% determinism}%
\label{grid_5x5}%
\end{subfigure}

\begin{subfigure}{.5\linewidth}
\includegraphics[height=5.3cm]{/Users/jurriaan/Documents/MScWiskunde/20180907_TNOdrive/Bayesian_network_repository/xdsl-benchmark-GeNIe-files/Grid_5x5/grid_5x5_ahd6_25000.png}
\caption{Grid 5x5 50\% evidence}%
\label{grid_3x3}%
\end{subfigure}\hfill%
\begin{subfigure}{.5\linewidth}
\includegraphics[height=5.3cm]{/Users/jurriaan/Documents/MScWiskunde/20180907_TNOdrive/Bayesian_network_repository/xdsl-benchmark-GeNIe-files/Grid_8x8/grid_8x8_ahd7_25000.png}
\caption{Grid 8x8 50\% evidence}%
\label{grid_5x5}%
\end{subfigure}

\vspace{0.75pc}
\caption{consistent underperformance of \ps using the \gls{HFS} approach. HFS allows \ps to construct a set $V$ of predetermined fixed size ($1$, $10$, $100$ or $1000$) of feasible states from the pruned BN in order to select (randomly) a state of the BN as the new sample.}
\label{results1}
\end{figure*}

\chapter{Conclusion}

\newpage
\chapter*{List of acronyms and symbols}
%List of abbreviations
\glsadd{MLN}
\glsadd{U}
\printglossaries

%Bibliography
\bibliographystyle{acm}
\bibliography{ref_msc_thesis}


\end{document}