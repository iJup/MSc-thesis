\documentclass{amsart}

%\usepackage{showlabels}
\usepackage{amssymb, amsmath}
\usepackage{mathrsfs}
\usepackage{amscd}
\usepackage{verbatim}
\usepackage{color}
\usepackage{xcolor}
\usepackage{enumerate}
\usepackage{a4wide}
\usepackage{dsfont}



%% new commands

%independent
\newcommand\indep{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}

%mathbf
\newcommand{\bfx}{{\mathbf{x}}}
\newcommand{\bfy}{{\mathbf{y}}}
\newcommand{\bfX}{{\mathbf{X}}}

%tab
\newcommand\tab[1][1cm]{\hspace*{#1}}

%indent
\setlength\parindent{0pt}

%%colors
%blue
\definecolor{azure}{rgb}{0.0, 0.5, 1.0}
\newcommand{\blue}[1]{\textcolor{azure}{#1}}
%light-blue
\definecolor{lightblue}{HTML}{00BFFF}
\newcommand{\lightblue}[1]{\textcolor{lightblue}{#1}}
%purple
\definecolor{deepfuchsia}{rgb}{0.76, 0.33, 0.76}
\newcommand{\purple}[1]{\textcolor{deepfuchsia}{#1}}
%blond
\definecolor{blond}{HTML}{C5B358}
\newcommand{\blond}[1]{\textcolor{blond}{#1}}

% theorems

\theoremstyle{plain}
\theoremstyle{remark}
\newtheorem{theorem}{\textbf{\em Theorem}}[section]
\newtheorem*{theorem*}{\textbf{\em Theorem}}
\newtheorem{remark}{}
\newtheorem*{remark*}{}
\newtheorem{example}[theorem]{Example}
\newtheorem{lemma}{\textbf{\em Lemma}}[section]
\newtheorem*{lemma*}{\textbf{\em Lemma}}
\newtheorem{definition}{Definition}
\newtheorem*{definition*}{\textbf{\em Def}}
\newtheorem{proposition}{\textbf{\em Proposition}}[section]
\newtheorem*{proposition*}{\textbf{\em Proposition}}
\newtheorem{corollary}{\textbf{\em Corollary}}[section]

\theoremstyle{plain}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{hypothesis}[theorem]{Hypothesis}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{question}[theorem]{Question}
%\numberwithin{equation}{section}
%\theoremstyle{problem}
%\numberwithin{equation}{}


% number systems

\def\bbN{{\mathbb N}}
\def\bbZ{{\mathbb Z}}
\def\bbQ{{\mathbb Q}}
\def\bbR{{\mathbb R}}
\def\bbC{{\mathbb C}}

\renewcommand{\P}{{\mathbb P}}


% probability notations

\newcommand{\A}{{\mathcal A}}
\newcommand{\B}{{\mathcal B}}
\newcommand{\C}{{\mathcal C}}
\newcommand{\E}{{\mathbb E}}
\newcommand{\F}{{\mathcal F}}
\newcommand{\G}{{\mathcal G}}
\renewcommand{\H}{{\mathcal H}}
\newcommand{\I}{{\mathcal{I}}}
\newcommand{\M}{{\mathcal M}}
\newcommand{\Q}{{\mathcal{Q}}}
\newcommand{\U}{{\mathcal{U}}}
\newcommand{\X}{{\mathcal{X}}}

\newcommand{\calP}{{\mathcal{P}}}
\newcommand{\Var}{{\text{Var}}}

% greek letters

\renewcommand{\a}{\alpha}
\renewcommand{\b}{\beta}
\newcommand{\g}{\gamma}
\renewcommand{\d}{\delta}
\newcommand{\eps}{\varepsilon}
\renewcommand{\l}{\lambda}
\newcommand{\om}{\omega}
\renewcommand{\O}{\Omega}
\renewcommand{\t}{\tau}
\renewcommand{\r}{\rho}
\newcommand{\Fub}{{\rm Fub}}
\newcommand{\Ito}{{\hbox{\rm It\^o}}}


% spaces

\renewcommand{\L}{L^2(0,1)}
\newcommand{\LH}{L^2(0,1;H)}
\renewcommand{\gg}{\g(\L,E)}
\newcommand{\ggH}{\g(\LH,E)}


% miscellaneous

\renewcommand{\Re}{\hbox{\rm Re}\,}
\renewcommand{\Im}{\hbox{\rm Im}\,}
\newcommand{\D}{{\mathcal D}}
\newcommand{\calL}{{\mathcal L}}
\newcommand{\n}{\Vert}
\newcommand{\one}{{{\bf 1}}}
\newcommand{\embed}{\hookrightarrow}
\newcommand{\lb}{\langle}
\newcommand{\rb}{\rangle}
\newcommand{\dps}{\displaystyle}
\renewcommand{\SS}{{\bf S}}
\newcommand{\limn}{\lim_{n\to\infty}}
\newcommand{\limk}{\lim_{k\to\infty}}
\newcommand{\limj}{\lim_{j\to\infty}}
\newcommand{\sumn}{\sum_{n\ge 1}}
\newcommand{\sumk}{\sum_{k\ge 1}}
\newcommand{\sumj}{\sum_{j\ge 1}}
\newcommand{\sumnN}{\sum_{n=1}^N}
\newcommand{\Ra}{\Rightarrow}
\newcommand{\LRa}{\Leftrightarrow}
\newcommand{\da}{\downarrow}
\newcommand{\wh}{\widehat}
\newcommand{\supp}{\text{\rm supp\,}}
\newcommand{\nn}{|\!|\!|}
\newcommand{\K}{\mathbb{K}}
\newcommand{\T}{\mathbb{T}}
\newcommand{\fil}{\{\F_t\}}

\let\emptyset\varnothing
\newcommand{\sign}{\text{sign}}

%spacing
\newcommand{\vs}{\vspace{0.75pc}}

\begin{document}
Bayes' rule:
\begin{align*}
\P(A_i|B) = \frac{\P(B|A_i) \cdot \P(A_i)}{\sum_j \P(B|A_j) \cdot \P(A_j)}
\end{align*}\\
Binary Bayes' rule:
\begin{align*}
\P(A|B) = \frac{\P(B|A) \cdot \P(A)}{ \P(B)}
\end{align*} \vs

\textbf{Scriptie Weikamp:}\vs

Main question: \textit{can we find a reliable (approximate) inference method that works theoretically as well as practically?} \\
\begin{itemize}
\item To what extent do the commonly used algorithms give reliable results?
\item To what extent is the BL method useful in doing inference in Bayesian networks? \\ \textit{Not useful}
\end{itemize}\vs

\underline{Chapter 2, section 2.1} \vs

\begin{definition*}\textbf{(Bayesian inference)}
The calculation of the \textit{posterior distribution}:
\begin{align*}
\P(X = x | E = e).
\end{align*}
\end{definition*}\vs

\underline{Chapter 2, section 2.2} \\
\begin{definition*}\textbf{(Chain rule)}
\begin{align*}
\P(X, Y) = \P(X | Y) \P(Y)
\end{align*}
\end{definition*}\vs

\begin{definition*}\textbf{ (General chain rule) }
\begin{align*}
\P(X_1, \ldots, X_n) = \sum{i=1}^n \P(X_i | X_1, \ldots , X_{n-1})
\end{align*}
\end{definition*}\vs

\begin{definition*}\textbf{(Conditionally independent)}
We say that $A$ and $B$ are conditionally independent given $C$ if
\begin{align*}
\P(A | B,C) = \P(A | C).
\end{align*}
Equivalently,
\begin{align*}
\P(A, B | C) = \P(A | C)\P(B| C).
\end{align*}
We write $(A \indep B\ |\ C)$
\end{definition*}\vs

\begin{definition*}\textbf{ (Local independencies) }
Local independencies, denoted by $\I_l(\G)$
\begin{align*}
For\ each\ X_i: (X_i \indep ND(X_i)\ |\ Pa(X_i)).
\end{align*}
\end{definition*}\vs

\begin{definition*}\textbf{ (Factorization - chain rule for Bayesian networks) }
\begin{align*}
\P(X_1, \ldots , X_n) = \prod_{i=1}^n \P(X_i\ |\ Pa(X_i))
\end{align*}
\end{definition*}\vs

\begin{definition*}\textbf{ (Factorization - chain rule for Bayesian networks) }
\begin{align*}
\P(X_1, \ldots , X_n) = \prod_{i=1}^n \P(X_i\ |\ Pa(X_i))
\end{align*}
\end{definition*}\vs

\underline{Chapter 3, section 3.2} \\
Inference methods:
\begin{itemize}
\item exact
\begin{itemize}
\item Variable elimination
\item Clique trees
\item Recursive conditioning
\end{itemize}
\item approximate
\begin{itemize}
\item Optimization
\begin{itemize}
\item \textit{Loopy belief Propagation} (lack of convergence, strong dependencies)
\end{itemize}
\item Sampling inference methods
\begin{itemize}
\item forward sampling
\item rejected sampling
\item likelihood sampling
\item importance sampling
\item MCMC
\begin{itemize}
\item Gibbs sampling
\item prune sampling
\end{itemize}
\end{itemize}
\end{itemize}
\end{itemize}\vs 

\begin{definition*}\textbf{ (Factor) }
Each $ \P(X_i\ |\ Pa(X_i))$ can be written as $\phi_i$.
\end{definition*}\vs

\begin{definition*}\textbf{ (Factor marginalisation) }
Let $\bfX$ be a set of variables and $Y \notin \bfX$ a variable. Let $\phi(\bfX,Y)$ be a factor. We define the factor marginalization of $Y$ in $\phi$, denoted $\sum_Y \phi$, to be a factor $\psi$ over $\bfX$ such that
\begin{align*}
\psi(X) = \sum_Y \phi(\bfX,Y).
\end{align*}
For example,
\begin{align*}
\P(C=0) = \sum_{A,B} \P(C=0 | B)\  \P(B | A)\ \P(A).
\end{align*}
\end{definition*}\vs

\begin{remark*}\textbf{(Variable Elimination)}
Choosing an elimination sequence, applying factor marginalization and finally normalizing we can obtain marginal probabilities $\P(X_i)$, where $X_i$ is a variable of interest in the Bayesian network.\vs

Drawbacks: if many connections $\implies$ large amount of factors $\psi$, which are products of $\phi_i$ $\implies$ exponential growth of the CPT of $\psi$. (memory intensive)
\end{remark*}\vs

\underline{Chapter 4, section 4.1} \\
\begin{definition*}\textbf{ (Collection of all CPT-indices of a BN) }
\begin{align*}
\C = \{ k(i): c_{k(i)} \text{ is a CPT-value in the $i$-th CPT $\P(X_i\ |\ Pa(X_i))$, indexed by $k(i)$, i=1, \ldots , n } \}
\end{align*}\vs
\end{definition*}\vs

\begin{definition*}\textbf{ (CPT-indices corresponding to state $\mathbf{x}$) }\begin{align*}
\C_\bfx
\end{align*}\vs
\end{definition*}\vs 

\begin{definition*}\textbf{ (States corresponding to a set of CPT-indices) }
Given a collection of CPT-indices $C$. The set $S_C$ of states $\bfx$ that use only the CPT-indices in the collection $C$ are called states corresponding to the CPT-indices.
\end{definition*}\vs 

\begin{definition*}\textbf{ (Pruning around $\bfx$, collection of pruned CPT-indices) }
\begin{align*}
&\C_{\bfx,p} = \emptyset\\
& \forall k(i) \in \C:
\begin{cases}
\text{add $k(i)$ to $\C_{\bfx, p}$} & \text{w.p. $1-c_{k(i)}$}\\
\text{do not add $k(i)$ to $\C_{\bfx, p}$} & \text{w.p. $c_{k(i)}$}\\
\end{cases}
\end{align*}
\end{definition*}\vs 

\begin{definition*}\textbf{ (Collection of non-pruned CPT-indices) }
\begin{align*}
&\C_{\bfx,n}:=\C \setminus \C_{\bfx,p}\\
\text{Note that: } &\C_\bfx \subset \C_{\bfx,n} \text{ and } \bfx \in S_{\C_{\bfx,n}}.
\end{align*}
\end{definition*}\vs 

\begin{definition*}\textbf{ (Uniform sampling over a set of states) }
Let $S_{\C_{\bfx,n}}$ be the set of feasible states corresponding to the CPT-indices which are not pruned. We define
\begin{align*}
\U(S_{\C_{\bfx,n}})
\end{align*}
as the uniform distribution over the states in $S_{\C_{\bfx,n}}$ and we write
\begin{align*}
\U(S_{\C_{\bfx,n}})(y) = \frac{1}{|S_{\C_{\bfx,n}}|}
\end{align*}
for the probability of sampling state $\bfy$ with respect to this uniform distribution.
\end{definition*}\vs 

\begin{remark*}\textbf{ (Remark) } - \textit{ (Could be proven more formally) }
With strictly positive probability we have that $\C_{\bfx^{(i-1)},n}$ contains all the non-zero indices in $\C$. Implying that $S_{\C_{\bfx^{(i-1)},n}}$ contains all feasible states of the BN.
\end{remark*}\vs

\begin{definition*}\textbf{ (Pruning around $\bfx$ and $\bfy$, collection of pruned CPT-indices) }
\begin{align*}
&\C_{\{\bfx,\bfy\},p} = \emptyset\\
& \forall k(i) \in \C:
\begin{cases}
\text{add $k(i)$ to $\C_{\bfx, p}$ when $k(i) \notin \C_\bfx, \C_\bfy$}  & \text{w.p. $1-c_{k(i)}$}\\
\text{do not add $k(i)$ to $\C_{\bfx, p}$} & \text{w.p. $c_{k(i)}$}\\
\end{cases}
\end{align*}
\end{definition*}\vs 

\begin{definition*}\textbf{ (Collection of non-pruned CPT-indices) }
\begin{align*}
\C_{\{\bfx,\bfy\},n}:=\C \setminus \C_{\{\bfx,\bfy\},p}\\
\end{align*}
\end{definition*}\vs 

\begin{definition*}\textbf{ (Total probability of transitioning from $\bfx \to \bfy$) }
\begin{align*}
Q(\bfx \to \bfy) = \sum_{j=1}^K Q_j(\bfx \to \bfy)
\end{align*}
\end{definition*}\vs 

\underline{Chapter 4, section 4.2} \\

The prune sampling algorithm is inspired by the MC-SAT algorithm [23]. \\

[23] Hoifung Poon and Pedro Domingos, \textit{Sound and efficient inference with probabilistic and deterministic dependencies}, Aaai, 2006, pp. 458-463. \\

\begin{definition*}\textbf{ (Non-trivial steps of prune sampling) }
\begin{enumerate}[1)]
\item Generating an initial state
\begin{itemize}
\item forward sampling: how many forward sampling walks will it take to generate one feasible solution?
\item random forward sampling
\item hybrid forward sampling 
\end{itemize}
\item Sampling uniformly over the pruned BN, i.e. sampling from the distribution $\U(S_{\C_{\bfx,n}})$.
\end{enumerate}
\end{definition*}\vspace{2pc} 

\begin{enumerate}[1)]
\item How is an initial state created? $\mathbf{x}^{(0)} \leftarrow \text{initial}$\\ \\ 
\textit{Hybrid forward sampling:} \\ \\ 
Basically \textit{forward sampling} but at each node $X_i$ either -- with probability $p$ -- the sampling distribution $\P(X_i\ |\ Pa(X_i)\ =\ \bfx )$ is chosen or -- with probability $1-p$ -- the uniform distribution over $\{x:\  \P(X_i\ |\ Pa(X_i)\ =\ \bfx)>0 \}$ is chosen. \\ \\
 \texttt{
initial = hybrid\_fw(network, \lightblue{evidence} = evidence, \lightblue{num\_walks} = num\_walks0, \lightblue{prob} = prob0) \\ \\
} 
To develop more intelligent ways to generate initial states: $[18]$. \\ \\
$[18]$ James D Park, \textit{Using weighted MAX-SAT engines to solve MPE}, Eighteenth national conference on artificial intelligence, 2002, pp. 682-687. \\
\item Sampling from $\U(S_{\C_{\mathbf{x,n}}})$
\begin{itemize}
\item Assuming we have sufficient memory, a breath first search approach can be used to list all feasible states of the pruned BN. From this collection we can easily draw uniformly a state. (in comparison to Gibbs sampling the uniform sampling step is relatively expensive)
\item To reduce computational effort: we propose to use random forward sampling to construct a set $S$ (of predetermined fixed size) of feasible states of the pruned BN. Subsequently a state from S can be sampled uniformly.
\item A more intelligent method, based on \textit{simulated annealing} is suggested by $[28]$. \\

$[28]$ Wei Wei, Jordan Erenrich, and Bart Selman, \textit{Towards efficient sampling: Exploiting random walk strategies}, Aaai, 2004, pp. 670-676.
\end{itemize}
\end{enumerate}

\vspace{2pc}
\makebox[\linewidth]{\rule{\textwidth}{0.6pt}} \\
\textbf{Prune Sampling Algorithm} \\
\makebox[\linewidth]{\rule{\textwidth}{0.4pt}} \\
\texttt{
\blue{def} sample\_states(data\_str\_node, col\_index) \\ \\
data\_str\_node = data\_str[node] \\ \\
data\_str = generate\_data\_str(network, ev, node\_list) \\ \\
} \\
\makebox[\linewidth]{\rule{\textwidth}{0.4pt}} \\

\texttt{
\blue{def} \blond{prune\_sampling} \\ \\
\tab data\_str = generate\_data\_structure(...) \\
\tab \blue{def} \blond{generate\_data\_structure} \\
\tab \tab \blue{def} \blond{create\_cpt\_shifts} \\ \\
\tab if heuristic == 1 \\
\tab \blue{def} \blond{random\_fw\_heuristic} \\
\tab \tab \blue{def} \blond{random\_walk} \\
\tab \tab \tab \blue{def} \blond{depth} \\
\tab \tab \tab \tab data\_str\_node = data\_str[node] \\
\tab \tab \tab \tab shifts = data\_str\_node['shifts'] \\ \\
\tab else \\
\tab \blue{def} \blond{bfs\_exhaust} \\
\tab \tab \blue{def} \blond{depth} \\ 
\tab \tab \tab shifts = data\_str\_node[`shifts'] \\
\tab \tab \tab pstates\_node = sample\_states(data\_str\_node, new\_col)
} \vspace{2pc}

Prune sampling algorithm
\begin{itemize}
\item Performance of prune sampling algorithm 
\begin{itemize}
\item Convergence of prior distribution $\Q$ to real distribution $\calP$
\item Weight of BN
\item Complexity
\item Methods to compare when dag-treewidth and query nodes
\begin{itemize}
\item Forward sampling
\item Metropolis sampling
\item Gibbs sampling
\item Prune sampling
\begin{itemize}
\item bfs\_exhaust
\item hybrid\_fw\_heuristics
\end{itemize}
\end{itemize}
\end{itemize}
\item Suggested Improvements
\begin{itemize}
\item Implementation 
\item Results
\end{itemize}
\item Complexity of Bayesian networks
\begin{itemize}
\item Applications of Bayesian networks
\begin{itemize}
\item Medicine
\item Finance
\end{itemize}
\end{itemize}
\end{itemize}

\newpage

\section{Monte Carlo error analysis}

\begin{align*}
\sigma^2 &= \langle y^2 \rangle - \langle y \rangle ^2 \\
\langle y \rangle &= \frac{1}{N} \sum_{i=1}^N y_i \\
\langle y^2 \rangle &= \frac{1}{N} \sum_{i=1}^N y_i^2 \\
\sigma_N &= \sqrt{ \frac{1}{N} \sum_{i=1}^N ( y_i - \bar{y}_N )^2 } \\
\log \sigma_N &= \frac{1}{2} \log \big( \frac{1}{N} \sum_{i=1}^N ( y_i - \bar{y}_N )^2 \big)
 \end{align*} \vspace{3pc}
 
Let $Y$ has a finite variance and $\Var(Y)=\sigma^2 < \infty$. In IID sampling, $\hat{\mu}_n$ is a random variable and it has its own mean and variance. The mean of $\hat{\mu}_n$ is
\begin{align*}
\E[\hat{\mu}_n] = \frac{1}{n} \sum_{i=1}^n \E[Y_i] = \mu
\end{align*}
The variance of $\hat{\mu}_n$ is
\begin{align*}
\E[(\hat{\mu}_n - \mu)^2 ] = \frac{\sigma^2}{n}.
\end{align*}
This gives us, $\sqrt{\E[(\hat{\mu}_n - \mu)^2 ]} = \sigma / \sqrt{n}$. To emphasize that the error is order $\sqrt{n}$ and to de-emphasize $\sigma$, we write root mean squared error, RMSE $ = O(\sqrt{n})$ as $n \to \infty$.

\vspace{3pc}

 
\begin{align*}
\P(Rain = T | GrassWet = T) &= \frac{\P(Rain = T, GrassWet = T)}{\P(GrassWet = T)} \\
&=  \frac{\sum_{S \in \{T,F\}} \P(rain = T, Sprinkler, GrassWet = T)}{\sum_{R,S \in \{T,F\}} \P(GrassWet = T, Rain, Sprinkler)} \\
&= \frac{0,00198_{TTT} + 0,1584_{TFT}}{0,00198_{TTT} + 0,288_{TTF} + 0,1584_{TFT} + 0.0_{TFF}} \\
&= 0,3577 \\
&= 1 - 0,6423
\end{align*}\vs

\begin{align*}
\P(GrassWet = T, Rain = T, Sprinkler = T) = &\P(GrassWet = T | Rain = T, Sprinkler = T) * \\ 
&\P(Sprinkler = T | Rain = T) * \P(Rain = T) \\
= & 0,99 * 0,01 * 0,2 \\
= & 0,00198
\end{align*} \vs

\newpage



\begin{definition*}\textbf{ (Literature about generating initial states) } \newline
[18] James D Park, \textit{Using Weighted MAX-SAT engines to solve MPE}, pp. 682-687
\end{definition*}\vs 

\begin{definition*}\textbf{ (Literature about uniformly sampling $\U(S_{\C_{\bfx,n}})
$) } \newline
[28] Wei Wei, Jordan Erenrich and Bart Selman, \textit{Towards efficient sampling: Exploiting random walk strategies}, Aaai 2004, pp. 670-676
\end{definition*}\vs 

New literature:
\begin{itemize}
\item Bayesian Networks and Decision Grpahs, Finn V. JEnsen and Thomas D. Nielsen
\item Probabilistic Graphical Models, Sucar, Luis Enrique
\end{itemize}


\end{document}